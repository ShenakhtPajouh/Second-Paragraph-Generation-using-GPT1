{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"equal_sgmnt_train.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mqXHWIaZgwmf","colab_type":"code","outputId":"dde370ec-f461-4cbc-8270-3b6a05aabd93","executionInfo":{"status":"ok","timestamp":1562335114388,"user_tz":-270,"elapsed":23673,"user":{"displayName":"kermit frog","photoUrl":"","userId":"14637721852906442593"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"41eLJ3OegzRE","colab_type":"code","outputId":"2227233a-58dc-47d4-c22d-d7dc45a477ea","executionInfo":{"status":"ok","timestamp":1562335114391,"user_tz":-270,"elapsed":23640,"user":{"displayName":"kermit frog","photoUrl":"","userId":"14637721852906442593"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%cd '/content/drive/My Drive/shared-works/Thread-1'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/shared-works/Thread-1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"02gueGDWg7Pl","colab_type":"code","outputId":"d3ccdbf2-773a-43ce-d6b1-ce37006a1059","executionInfo":{"status":"ok","timestamp":1562334848136,"user_tz":-270,"elapsed":30888,"user":{"displayName":"kermit frog","photoUrl":"","userId":"14637721852906442593"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["!pip install ftfy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (5.5.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.1.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M0Ur_ssMgt-u","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import pickle\n","from model import Transformer\n","from utils import iter_data, Logger\n","import time\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gSRsBWTMg9Ar","colab_type":"code","colab":{}},"source":["def save(model, train_loss_results, validation_loss_results, cnt):\n","    with open('./Data/interpretation/equal_segment/pickle/train_loss_results.pkl', 'wb') as pkl:\n","        pickle.dump(train_loss_results, pkl)\n","\n","    with open('./Data/interpretation/equal_segment/pickle/validation_loss_results.pkl', 'wb') as pkl:\n","        pickle.dump(validation_loss_results, pkl)\n","\n","    model.save_weights(\"./checkpoints/interpretation/equal_segment/model/cp-{}.ckpt\".format(format(cnt)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghLZgCQzg_gc","colab_type":"code","colab":{}},"source":["def format(x, max_len=4):\n","    x = str(x)\n","    return \"0\" * (max_len - len(x)) + x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U20F0EYYhB2M","colab_type":"code","colab":{}},"source":["def STLR(t, cut_frac = 0.1, ratio = 32, lr_max = 0.002, T = 1400000):\n","    cut = int(T * cut_frac)\n","    p = t / cut if t < cut else 1 - (t - cut) / (cut * (ratio - 1))\n","    lr = lr_max * (1 + p * (ratio - 1)) / ratio\n","    return lr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"navYdbCQhDx6","colab_type":"code","colab":{}},"source":["def decay(lr, t):\n","    lr -= lr * (1 / (t ** 0.5))\n","    return lr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6kbQNf_1cAV","colab_type":"code","colab":{}},"source":["def train(model, val_data_len, learning_rate=0.00025, \n","          n_epochs=100, n_embd = 768, n_vocab = 40478, n_batch=64, n_ctx=512, n_special = 1, n_segment = 3,\n","          train_steps=100, validation_steps=5000, save_steps=5000, log_path='train.log', lr_fn = 'STLR', cnt=0):\n","    \n","    \"\"\"\n","        X : (batch size, seq len, 3 (IDs and positions and segments)) -> tokens\n","        M1: (batch size, seq len) -> masks for getting 2nd paragraph in input tokens\n","        M2: (batch size, seq len) -> masks for getting 2nd paragraph in predicted tokens\n","    \"\"\"\n","    \n","    \n","    def parse_function(data_record):\n","        features={\n","            'triple': tf.VarLenFeature(tf.int64),\n","            'tokens_mask': tf.VarLenFeature(tf.int64),\n","            'preds_mask': tf.VarLenFeature(tf.int64),\n","            'book_id': tf.FixedLenFeature([], tf.int64),\n","            'counter': tf.FixedLenFeature([], tf.int64),\n","            'file_id': tf.FixedLenFeature([], tf.int64)\n","        }\n","        \n","        example=tf.parse_single_example(data_record, features)\n","        tp=example['triple'].values\n","        tp=tp-1\n","        tm=example['tokens_mask'].values\n","        tm=tm-1\n","        pm=example['preds_mask'].values\n","        pm=pm-1\n","        md=(example['book_id'], example['counter'], example['file_id'])\n","        print(\".............\")\n","        print(type(tp), type(tm), type(pm), type(md))\n","        \n","        return (tp, tm, pm, md[0], md[1], md[2])\n","        \n","    def create_dataset(n_files, n_batch, train=True):\n","        tfrecord_files=[]\n","        if train:\n","            for b in range(n_files-1):\n","                f_name='/content/drive/My Drive/shared-works/Thread-1/Data/interpretation/equal_segment/'+str(b)+'.tfrecord'\n","                tfrecord_files.append(f_name)\n","                \n","        else:\n","            f_name='/content/drive/My Drive/shared-works/Thread-1/Data/interpretation/equal_segment/'+str(n_files-1)+'.tfrecord'\n","            tfrecord_files.append(f_name)\n","\n","        dataset=tf.data.TFRecordDataset(tfrecord_files)\n","        dataset=dataset.map(parse_function)\n","#         dataset=dataset.shuffle(buffer_size=10)\n","        dataset=dataset.padded_batch(batch_size=n_batch, padded_shapes=((None,),(None,),(None,),(),(),()), drop_remainder=True)\n","        dataset=dataset.repeat()\n","        return dataset\n","    \n","    tf.reset_default_graph()\n","    \n","    t_dataset=create_dataset(7, n_batch)\n","    t_iterator=t_dataset.make_one_shot_iterator()\n","    X_t,M1_t,M2_t,md_t0, md_t1, md_t2=t_iterator.get_next()\n","    \n","    v_dataset=create_dataset(7, n_batch, train=False)\n","    v_iterator=v_dataset.make_one_shot_iterator()\n","    X_v,M1_v,M2_v,md_v0, md_v1, md_v2=v_iterator.get_next()\n","    \n","    t_saveable = tf.data.experimental.make_saveable_from_iterator(t_iterator)\n","    tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, t_saveable)\n","    \n","    v_saveable = tf.data.experimental.make_saveable_from_iterator(v_iterator)\n","    tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, v_saveable)\n","        \n","        \n","\n","    \n","#     tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, model.variables)\n","        \n","    X = tf.placeholder(tf.int32, [None, None, 3])\n","    M1 = tf.placeholder(tf.int32, [None, None])\n","    M2 = tf.placeholder(tf.int32, [None, None])\n","    logits, losses = model([X, M1, M2])\n","    # Create model's graph\n","\n","    \n","\n","    lr = tf.placeholder(tf.float32, shape=[])\n","    optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n","    # Define Optimizer\n","    \n","    \n","    real_grads = tf.gradients(losses, model.variables)\n","    real_grads[0] = tf.convert_to_tensor(real_grads[0])\n","#     fake_grads = [tf.zeros_like(grad, dtype = tf.float32) for grad in real_grads]\n","    \n","#     def set_zero():\n","#         return real_grads\n","    \n","#     def preserve():\n","#         return fake_grads\n","    \n","#     limit = tf.constant(5.64)\n","#     grads = tf.cond(tf.greater(losses, limit), set_zero, preserve)\n","    grads_and_vars = zip(real_grads, model.variables)\n","    capped_grads_and_vars = [(tf.clip_by_norm(grad, 0.25), var) for grad, var in grads_and_vars]\n","    train_op = optimizer.apply_gradients(capped_grads_and_vars)\n","    # Create nodes for applying gradients\n","    \n","\n","    print(tf.get_collection(tf.GraphKeys.SAVEABLE_OBJECTS))\n","    print(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n","    \n","    \n","    sess = tf.Session()\n","    tf.keras.backend.set_session(sess)\n","    sess.run(tf.global_variables_initializer())\n","    \n","    saver=tf.train.Saver(var_list=tf.get_collection(tf.GraphKeys.SAVEABLE_OBJECTS), max_to_keep=0)\n","    \n","    if cnt==0:\n","        \n","        model.load_weights('./checkpoints/Segment/cp-0001.ckpt')\n","        train_loss_results=[]\n","        validation_loss_results=[]\n","    \n","    if cnt>0:\n","        \n","#         tf.reset_default_graph()\n","#         imported_graph = tf.train.import_meta_graph('./checkpoints/language_model/my-model0.meta')\n","#         imported_graph.restore(sess, './checkpoints/language_model/my-model0')\n","        \n","        \n","        print('before')\n","        saver.restore(sess, \"./checkpoints/interpretation/equal_segment/iterator/svble-{}\".format(format(cnt)))\n","        print('after')\n","        load_path=\"./checkpoints/interpretation/equal_segment/model/cp-{}.ckpt\".format(format(cnt))\n","        model.load_weights(load_path)\n","        with open('./Data/interpretation/equal_segment/pickle/train_loss_results.pkl', 'rb') as pkl:\n","            train_loss_results = pickle.load(pkl)\n","        with open('./Data/interpretation/equal_segment/pickle/validation_loss_results.pkl', 'rb') as pkl:\n","            validation_loss_results = pickle.load(pkl)\n","    \n","\n","    train_losses = []\n","    \n","\n","    \n","\n","    step=370000\n","#     step = 510000\n","#     cnt = 85\n","    max_loss = 0\n","#     train_generator = iter_data(n_batch, n_epochs)\n","    logger = Logger(path=log_path)\n","    start = time.time()\n","    \n","    np.set_printoptions(precision = 4)\n","\n","    while True:\n","        step += 1\n","        if step%100==0:\n","            print('step:',step)\n","        \n","        tokenss, maskss1, maskss2, m1, m2, m3=sess.run([X_t,M1_t,M2_t,md_t0, md_t1, md_t2])\n","        tokens=np.asarray(tokenss).reshape([n_batch,-1,3])\n","        masks1=np.asarray(maskss1)\n","        masks2=np.asarray(maskss2)\n","#         print('shapes')\n","#         print(tokens)\n","#         print(masks1)\n","#         print(masks2)\n","#         print(tokens.shape)\n","#         print(masks1.shape)\n","#         print(masks2.shape)\n","        metadata=(m1,m2,m3)\n","        if lr_fn == 'STLR':\n","            _, train_loss, gradients = sess.run([train_op, losses, real_grads], {X: tokens, M1: masks1, M2: masks2, lr: STLR(step)})\n","\n","        else:\n","            _, train_loss, gradients = sess.run([train_op, losses, real_grads], {X: tokens, M1: masks1, M2: masks2, lr: learning_rate})   \n","            \n","\n","        if train_loss > max_loss:\n","            max_loss = train_loss\n","            print('\\n {} {} , {}\\n'.format(step, metadata, np.power(2, train_loss)))\n","            \n","        else:\n","            train_losses.append(train_loss)\n","            \n","        if step % 1000 == 1:\n","            print('\\n' + str(np.linalg.norm(gradients[3])) + \"  \" + str(np.linalg.norm(gradients[0])) + '\\n')\n","        \n","        if step % train_steps == 0:\n","            if lr_fn != 'STLR':\n","                learning_rate = decay(learning_rate, step)\n","\n","            train_loss_results.append(sum(train_losses) / len(train_losses))\n","            train_losses = []\n","            logger.log(step=step, train_loss=train_loss_results[-1], time=time.time() - start)\n","            print('Step: {} -- Time: {} => ppl: {}'.format(step, int(time.time() - start), np.power(2, train_loss_results[-1])))\n","\n","        if step % validation_steps == 0:\n","            print('validation')\n","#             validation_generator = iter_data(n_batch, train=False)\n","            validation_losses = []\n","            for rr in range(val_data_len):\n","                validation_tokenss, validation_maskss1, validation_maskss2, _,_,_=sess.run([X_v,M1_v,M2_v,md_v0, md_v1, md_v2])\n","                validation_tokens=np.asarray(validation_tokenss).reshape([n_batch,-1,3])\n","                validation_masks1=np.asarray(validation_maskss1)\n","                validation_masks2=np.asarray(validation_maskss2)\n","                validation_losses.append(sess.run(losses, {X: validation_tokens, M1: validation_masks1, M2: validation_masks2}))\n","\n","            validation_loss_results.append(sum(validation_losses) / len(validation_losses))\n","            logger.log(step=step, validation_loss=validation_loss_results[-1], time=time.time() - start)\n","            print('### Step: {} -- Time: {} => ppl: {}'.format(step, int(time.time() - start), np.power(2, validation_loss_results[-1])))\n","\n","        if step % save_steps == 0:\n","            cnt += 1\n","            print('cnt',cnt)\n","            save(model, train_loss_results, validation_loss_results, cnt)\n","            save_path=saver.save(sess, \"./checkpoints/interpretation/equal_segment/iterator/svble-{}\".format(format(cnt)))\n","                "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2Ck4v1DhKso","colab_type":"code","colab":{}},"source":["model = Transformer(\"Model\", 40478)\n","val_data_len=500\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8josLpOOU7o","colab_type":"code","outputId":"22819a53-7f06-4447-bd14-352ff2c6ac8a","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train(model, val_data_len,n_batch = 2, n_epochs = 1, cnt=74)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0705 13:58:37.042046 140359178696576 deprecation.py:323] From <ipython-input-8-a5a44df9df52>:56: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"],"name":"stderr"},{"output_type":"stream","text":[".............\n","<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'> <class 'tuple'>\n",".............\n","<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'> <class 'tuple'>\n"],"name":"stdout"},{"output_type":"stream","text":["W0705 13:58:38.047585 140359178696576 deprecation_wrapper.py:119] From /content/drive/My Drive/shared-works/Thread-1/model.py:55: The name tf.keras.initializers.random_normal is deprecated. Please use tf.compat.v1.keras.initializers.random_normal instead.\n","\n","W0705 13:58:38.049215 140359178696576 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0705 13:58:38.434679 140359178696576 deprecation_wrapper.py:119] From /content/drive/My Drive/shared-works/Thread-1/model.py:124: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","W0705 13:58:38.536351 140359178696576 deprecation_wrapper.py:119] From /content/drive/My Drive/shared-works/Thread-1/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n","\n","W0705 13:58:43.536848 140359178696576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0705 13:58:43.585206 140359178696576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:253: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["[<tensorflow.python.data.experimental.ops.iterator_ops._Saveable object at 0x7fa7012d8f28>, <tensorflow.python.data.experimental.ops.iterator_ops._Saveable object at 0x7fa7012e4710>]\n","[<tf.Variable 'Model/embedding/we:0' shape=(40994, 768) dtype=float32>, <tf.Variable 'Model/h//attn/conv1d/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h//attn/conv1d/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h//attn/conv1d_1/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h//attn/conv1d_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h//mlp/conv1d_2/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h//mlp/conv1d_2/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h//mlp/conv1d_3/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h//mlp/conv1d_3/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_1//attn/conv1d_4/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_1//attn/conv1d_4/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_1//attn/conv1d_5/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_1//attn/conv1d_5/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_1//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_1//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_1//mlp/conv1d_6/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_1//mlp/conv1d_6/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_1//mlp/conv1d_7/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_1//mlp/conv1d_7/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_1//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_1//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_2//attn/conv1d_8/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_2//attn/conv1d_8/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_2//attn/conv1d_9/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_2//attn/conv1d_9/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_2//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_2//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_2//mlp/conv1d_10/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_2//mlp/conv1d_10/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_2//mlp/conv1d_11/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_2//mlp/conv1d_11/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_2//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_2//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_3//attn/conv1d_12/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_3//attn/conv1d_12/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_3//attn/conv1d_13/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_3//attn/conv1d_13/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_3//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_3//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_3//mlp/conv1d_14/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_3//mlp/conv1d_14/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_3//mlp/conv1d_15/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_3//mlp/conv1d_15/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_3//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_3//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_4//attn/conv1d_16/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_4//attn/conv1d_16/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_4//attn/conv1d_17/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_4//attn/conv1d_17/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_4//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_4//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_4//mlp/conv1d_18/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_4//mlp/conv1d_18/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_4//mlp/conv1d_19/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_4//mlp/conv1d_19/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_4//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_4//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_5//attn/conv1d_20/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_5//attn/conv1d_20/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_5//attn/conv1d_21/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_5//attn/conv1d_21/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_5//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_5//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_5//mlp/conv1d_22/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_5//mlp/conv1d_22/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_5//mlp/conv1d_23/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_5//mlp/conv1d_23/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_5//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_5//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_6//attn/conv1d_24/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_6//attn/conv1d_24/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_6//attn/conv1d_25/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_6//attn/conv1d_25/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_6//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_6//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_6//mlp/conv1d_26/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_6//mlp/conv1d_26/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_6//mlp/conv1d_27/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_6//mlp/conv1d_27/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_6//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_6//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_7//attn/conv1d_28/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_7//attn/conv1d_28/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_7//attn/conv1d_29/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_7//attn/conv1d_29/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_7//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_7//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_7//mlp/conv1d_30/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_7//mlp/conv1d_30/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_7//mlp/conv1d_31/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_7//mlp/conv1d_31/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_7//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_7//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_8//attn/conv1d_32/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_8//attn/conv1d_32/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_8//attn/conv1d_33/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_8//attn/conv1d_33/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_8//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_8//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_8//mlp/conv1d_34/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_8//mlp/conv1d_34/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_8//mlp/conv1d_35/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_8//mlp/conv1d_35/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_8//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_8//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_9//attn/conv1d_36/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_9//attn/conv1d_36/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_9//attn/conv1d_37/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_9//attn/conv1d_37/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_9//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_9//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_9//mlp/conv1d_38/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_9//mlp/conv1d_38/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_9//mlp/conv1d_39/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_9//mlp/conv1d_39/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_9//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_9//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_10//attn/conv1d_40/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_10//attn/conv1d_40/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_10//attn/conv1d_41/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_10//attn/conv1d_41/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_10//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_10//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_10//mlp/conv1d_42/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_10//mlp/conv1d_42/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_10//mlp/conv1d_43/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_10//mlp/conv1d_43/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_10//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_10//ln_2/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_11//attn/conv1d_44/w:0' shape=(1, 768, 2304) dtype=float32>, <tf.Variable 'Model/h_11//attn/conv1d_44/b:0' shape=(2304,) dtype=float32>, <tf.Variable 'Model/h_11//attn/conv1d_45/w:0' shape=(1, 768, 768) dtype=float32>, <tf.Variable 'Model/h_11//attn/conv1d_45/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_11//ln_1/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_11//ln_1/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_11//mlp/conv1d_46/w:0' shape=(1, 768, 3072) dtype=float32>, <tf.Variable 'Model/h_11//mlp/conv1d_46/b:0' shape=(3072,) dtype=float32>, <tf.Variable 'Model/h_11//mlp/conv1d_47/w:0' shape=(1, 3072, 768) dtype=float32>, <tf.Variable 'Model/h_11//mlp/conv1d_47/b:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_11//ln_2/g:0' shape=(768,) dtype=float32>, <tf.Variable 'Model/h_11//ln_2/b:0' shape=(768,) dtype=float32>]\n"],"name":"stdout"},{"output_type":"stream","text":["W0705 13:58:51.820018 140359178696576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["before\n","after\n","\n"," 370001 (array([ 1257, 10081]), array([436, 266]), array([1, 1])) , 6.468842877371718\n","\n","\n","1.563  3.1315894\n","\n","\n"," 370002 (array([25762,  2038]), array([1155,  288]), array([1, 1])) , 14.131115044541147\n","\n","\n"," 370003 (array([ 1366, 17870]), array([3204,  338]), array([1, 1])) , 16.299456964696443\n","\n","\n"," 370013 (array([43235,  9785]), array([ 364, 2079]), array([1, 1])) , 17.217200718002687\n","\n","\n"," 370015 (array([ 1921, 26536]), array([1200,   27]), array([1, 1])) , 32.88426943187013\n","\n","step: 370100\n","Step: 370100 -- Time: 39 => ppl: 11.032262153247041\n","\n"," 370141 (array([18734, 51294]), array([ 678, 2747]), array([1, 1])) , 47.740846831727936\n","\n","step: 370200\n","Step: 370200 -- Time: 68 => ppl: 11.234475561141181\n","step: 370300\n","Step: 370300 -- Time: 98 => ppl: 11.689617628251975\n","step: 370400\n","Step: 370400 -- Time: 127 => ppl: 11.460643995319549\n","step: 370500\n","Step: 370500 -- Time: 157 => ppl: 10.456807423179255\n","step: 370600\n","Step: 370600 -- Time: 186 => ppl: 10.262371862681386\n","step: 370700\n","Step: 370700 -- Time: 213 => ppl: 10.257135940987645\n","step: 370800\n","Step: 370800 -- Time: 243 => ppl: 10.948359266225568\n","step: 370900\n","Step: 370900 -- Time: 272 => ppl: 10.548064656409418\n","step: 371000\n","Step: 371000 -- Time: 301 => ppl: 11.17395238953046\n","\n","1.253348  2.0309367\n","\n","\n"," 371093 (array([2126, 9377]), array([ 918, 1606]), array([1, 1])) , 48.03321226314583\n","\n","step: 371100\n","Step: 371100 -- Time: 332 => ppl: 11.286688420763477\n","step: 371200\n","Step: 371200 -- Time: 362 => ppl: 11.473753637964746\n","step: 371300\n","Step: 371300 -- Time: 391 => ppl: 10.843288710280042\n","step: 371400\n","Step: 371400 -- Time: 423 => ppl: 11.086219789753901\n","step: 371500\n","Step: 371500 -- Time: 456 => ppl: 10.608533113342759\n","step: 371600\n","Step: 371600 -- Time: 485 => ppl: 10.928335490723507\n","step: 371700\n","Step: 371700 -- Time: 517 => ppl: 11.078887826643838\n","step: 371800\n","Step: 371800 -- Time: 548 => ppl: 10.937526713035599\n","step: 371900\n","Step: 371900 -- Time: 580 => ppl: 11.084993601356162\n","step: 372000\n","Step: 372000 -- Time: 609 => ppl: 11.13513753124575\n","\n","1.6620426  2.746918\n","\n","step: 372100\n","Step: 372100 -- Time: 640 => ppl: 11.195309198085742\n","step: 372200\n","Step: 372200 -- Time: 670 => ppl: 10.708098534188826\n","step: 372300\n","Step: 372300 -- Time: 697 => ppl: 11.208540741514009\n","step: 372400\n","Step: 372400 -- Time: 725 => ppl: 9.871124203436029\n","step: 372500\n","Step: 372500 -- Time: 754 => ppl: 11.148158990586081\n","step: 372600\n","Step: 372600 -- Time: 786 => ppl: 11.26133832943341\n","step: 372700\n","Step: 372700 -- Time: 816 => ppl: 10.281224364531905\n","step: 372800\n","Step: 372800 -- Time: 844 => ppl: 12.17475022634783\n","step: 372900\n","Step: 372900 -- Time: 876 => ppl: 10.884143457313973\n","step: 373000\n","Step: 373000 -- Time: 907 => ppl: 10.885601341961655\n","\n","1.7583894  2.8617613\n","\n","step: 373100\n","Step: 373100 -- Time: 936 => ppl: 11.220844113307106\n","step: 373200\n","Step: 373200 -- Time: 967 => ppl: 10.601885313572541\n","step: 373300\n","Step: 373300 -- Time: 998 => ppl: 10.90836856365576\n","step: 373400\n","Step: 373400 -- Time: 1024 => ppl: 10.363433682610541\n","step: 373500\n","Step: 373500 -- Time: 1052 => ppl: 10.168699293236196\n","step: 373600\n","Step: 373600 -- Time: 1082 => ppl: 11.05355807909814\n","step: 373700\n","Step: 373700 -- Time: 1112 => ppl: 10.109259392158892\n","step: 373800\n","Step: 373800 -- Time: 1142 => ppl: 10.886675716173821\n","step: 373900\n","Step: 373900 -- Time: 1171 => ppl: 11.435974825793476\n","step: 374000\n","Step: 374000 -- Time: 1199 => ppl: 10.80769789621841\n","\n","1.5138228  2.5017385\n","\n","step: 374100\n","Step: 374100 -- Time: 1231 => ppl: 10.822541928504522\n","step: 374200\n","Step: 374200 -- Time: 1262 => ppl: 10.48013213417563\n","step: 374300\n","Step: 374300 -- Time: 1290 => ppl: 10.293660772942573\n","step: 374400\n","Step: 374400 -- Time: 1319 => ppl: 10.458126768376227\n","step: 374500\n","Step: 374500 -- Time: 1349 => ppl: 10.141865512257787\n","step: 374600\n","Step: 374600 -- Time: 1381 => ppl: 11.88175073872902\n","step: 374700\n","Step: 374700 -- Time: 1411 => ppl: 11.23154111602431\n","step: 374800\n","Step: 374800 -- Time: 1439 => ppl: 10.809988739487416\n","step: 374900\n","Step: 374900 -- Time: 1468 => ppl: 10.903760148507466\n","step: 375000\n","Step: 375000 -- Time: 1497 => ppl: 10.545946227194547\n","validation\n","### Step: 375000 -- Time: 1545 => ppl: 11.040672248728615\n","cnt 75\n","\n","1.2209382  2.0791383\n","\n","step: 375100\n","Step: 375100 -- Time: 1580 => ppl: 10.331473182244668\n","step: 375200\n","Step: 375200 -- Time: 1609 => ppl: 10.681819877767284\n","step: 375300\n","Step: 375300 -- Time: 1639 => ppl: 11.158928420814906\n","step: 375400\n","Step: 375400 -- Time: 1667 => ppl: 10.14266135900697\n","\n"," 375464 (array([ 1259, 51407]), array([2287,    8]), array([1, 1])) , 125.44544455363969\n","\n","step: 375500\n","Step: 375500 -- Time: 1699 => ppl: 10.39623441747798\n","step: 375600\n","Step: 375600 -- Time: 1728 => ppl: 10.349330603422937\n","step: 375700\n","Step: 375700 -- Time: 1758 => ppl: 10.998924310693573\n","step: 375800\n","Step: 375800 -- Time: 1786 => ppl: 10.758874010438719\n","step: 375900\n","Step: 375900 -- Time: 1816 => ppl: 11.82475030530412\n","step: 376000\n","Step: 376000 -- Time: 1845 => ppl: 10.334267211046388\n","\n","1.8156716  2.6110773\n","\n","step: 376100\n","Step: 376100 -- Time: 1874 => ppl: 10.633568697786831\n","step: 376200\n","Step: 376200 -- Time: 1904 => ppl: 10.894224078358294\n","step: 376300\n","Step: 376300 -- Time: 1934 => ppl: 11.129059886510467\n","step: 376400\n","Step: 376400 -- Time: 1961 => ppl: 10.201510574104287\n","step: 376500\n","Step: 376500 -- Time: 1989 => ppl: 10.838469491088205\n","step: 376600\n","Step: 376600 -- Time: 2017 => ppl: 10.954329032950074\n","step: 376700\n","Step: 376700 -- Time: 2047 => ppl: 11.038647188422631\n","step: 376800\n","Step: 376800 -- Time: 2076 => ppl: 10.97303655127877\n","step: 376900\n","Step: 376900 -- Time: 2105 => ppl: 10.68880472471971\n","step: 377000\n","Step: 377000 -- Time: 2134 => ppl: 11.157346853735536\n","\n","1.4000553  2.2342353\n","\n","step: 377100\n","Step: 377100 -- Time: 2165 => ppl: 11.55886159834385\n","step: 377200\n","Step: 377200 -- Time: 2194 => ppl: 11.136886358177145\n","step: 377300\n","Step: 377300 -- Time: 2224 => ppl: 10.49015478154155\n","step: 377400\n","Step: 377400 -- Time: 2252 => ppl: 11.136331543142434\n","step: 377500\n","Step: 377500 -- Time: 2280 => ppl: 10.779747117084298\n","step: 377600\n","Step: 377600 -- Time: 2308 => ppl: 10.57627404296122\n","step: 377700\n","Step: 377700 -- Time: 2340 => ppl: 10.8277167131183\n","step: 377800\n","Step: 377800 -- Time: 2369 => ppl: 10.063334196096084\n","step: 377900\n","Step: 377900 -- Time: 2398 => ppl: 10.5088206038005\n","step: 378000\n","Step: 378000 -- Time: 2426 => ppl: 10.419135480668269\n","\n","2.4432857  3.8541238\n","\n","step: 378100\n","Step: 378100 -- Time: 2453 => ppl: 10.387403796137386\n","step: 378200\n","Step: 378200 -- Time: 2481 => ppl: 10.68048786262761\n","step: 378300\n","Step: 378300 -- Time: 2509 => ppl: 10.311312985884168\n","step: 378400\n","Step: 378400 -- Time: 2537 => ppl: 10.892611020915483\n","step: 378500\n","Step: 378500 -- Time: 2567 => ppl: 11.031177675922352\n","step: 378600\n","Step: 378600 -- Time: 2597 => ppl: 11.10556558266214\n","step: 378700\n","Step: 378700 -- Time: 2630 => ppl: 10.581345719953699\n","step: 378800\n","Step: 378800 -- Time: 2658 => ppl: 10.472899183598821\n","step: 378900\n","Step: 378900 -- Time: 2689 => ppl: 10.380301650391774\n","step: 379000\n","Step: 379000 -- Time: 2717 => ppl: 10.671531148532878\n","\n","1.8072968  2.9634652\n","\n","step: 379100\n","Step: 379100 -- Time: 2748 => ppl: 11.330014050870185\n","step: 379200\n","Step: 379200 -- Time: 2779 => ppl: 11.197888739410395\n","step: 379300\n","Step: 379300 -- Time: 2807 => ppl: 11.038343931325182\n","step: 379400\n","Step: 379400 -- Time: 2836 => ppl: 10.00350503207207\n","step: 379500\n","Step: 379500 -- Time: 2864 => ppl: 10.257021201276334\n","step: 379600\n","Step: 379600 -- Time: 2892 => ppl: 11.532812331623571\n","step: 379700\n","Step: 379700 -- Time: 2921 => ppl: 10.591131825044648\n","step: 379800\n","Step: 379800 -- Time: 2948 => ppl: 10.870453644297474\n","step: 379900\n","Step: 379900 -- Time: 2979 => ppl: 10.089802305162673\n","step: 380000\n","Step: 380000 -- Time: 3011 => ppl: 11.315296653763554\n","validation\n","### Step: 380000 -- Time: 3058 => ppl: 10.88076575372263\n","cnt 76\n","\n","2.1596582  3.9688544\n","\n","step: 380100\n","Step: 380100 -- Time: 3090 => ppl: 10.274571520582294\n","step: 380200\n","Step: 380200 -- Time: 3119 => ppl: 10.951926670955793\n","step: 380300\n","Step: 380300 -- Time: 3148 => ppl: 11.025534099422627\n","step: 380400\n","Step: 380400 -- Time: 3179 => ppl: 10.702189662902493\n","step: 380500\n","Step: 380500 -- Time: 3210 => ppl: 10.90091729116041\n","step: 380600\n","Step: 380600 -- Time: 3238 => ppl: 10.526210214010339\n","step: 380700\n","Step: 380700 -- Time: 3269 => ppl: 10.87894243334611\n","step: 380800\n","Step: 380800 -- Time: 3299 => ppl: 10.574185256086448\n","step: 380900\n","Step: 380900 -- Time: 3327 => ppl: 10.490432819068626\n","step: 381000\n","Step: 381000 -- Time: 3357 => ppl: 10.644355449272027\n","\n","2.2192473  4.388666\n","\n","step: 381100\n","Step: 381100 -- Time: 3387 => ppl: 10.814173253654397\n","step: 381200\n","Step: 381200 -- Time: 3416 => ppl: 10.67358625621791\n","step: 381300\n","Step: 381300 -- Time: 3444 => ppl: 10.72902811515523\n","step: 381400\n","Step: 381400 -- Time: 3474 => ppl: 11.1216028959458\n","step: 381500\n","Step: 381500 -- Time: 3503 => ppl: 10.303257920872245\n","step: 381600\n","Step: 381600 -- Time: 3530 => ppl: 10.723051634668954\n","step: 381700\n","Step: 381700 -- Time: 3561 => ppl: 10.646399710965326\n","step: 381800\n","Step: 381800 -- Time: 3590 => ppl: 10.867628854677571\n","step: 381900\n","Step: 381900 -- Time: 3619 => ppl: 11.177298861584347\n","step: 382000\n","Step: 382000 -- Time: 3647 => ppl: 10.744968259014186\n","\n","3.0803587  5.2094955\n","\n","step: 382100\n","Step: 382100 -- Time: 3676 => ppl: 11.188288686454111\n","step: 382200\n","Step: 382200 -- Time: 3707 => ppl: 10.658045865326208\n","step: 382300\n","Step: 382300 -- Time: 3736 => ppl: 10.816847612255376\n","step: 382400\n","Step: 382400 -- Time: 3765 => ppl: 10.455993510354356\n","step: 382500\n","Step: 382500 -- Time: 3795 => ppl: 10.596269893693984\n","step: 382600\n","Step: 382600 -- Time: 3823 => ppl: 10.426489218587298\n","step: 382700\n","Step: 382700 -- Time: 3849 => ppl: 10.482067008629262\n","step: 382800\n","Step: 382800 -- Time: 3879 => ppl: 11.295102037224407\n","step: 382900\n","Step: 382900 -- Time: 3909 => ppl: 10.502806903499852\n","step: 383000\n","Step: 383000 -- Time: 3938 => ppl: 10.900417194741207\n","\n","0.88990456  1.9508058\n","\n","step: 383100\n","Step: 383100 -- Time: 3968 => ppl: 10.545013200562925\n","step: 383200\n","Step: 383200 -- Time: 3998 => ppl: 11.073353996044494\n","step: 383300\n","Step: 383300 -- Time: 4029 => ppl: 10.825471963558934\n","step: 383400\n","Step: 383400 -- Time: 4059 => ppl: 11.120552411918082\n","step: 383500\n","Step: 383500 -- Time: 4090 => ppl: 10.92211106181627\n","step: 383600\n","Step: 383600 -- Time: 4118 => ppl: 11.049950110013382\n","step: 383700\n","Step: 383700 -- Time: 4151 => ppl: 10.859630872967815\n","step: 383800\n","Step: 383800 -- Time: 4180 => ppl: 10.569107037800546\n","step: 383900\n","Step: 383900 -- Time: 4210 => ppl: 10.278780658184326\n","step: 384000\n","Step: 384000 -- Time: 4239 => ppl: 10.843607440657651\n","\n","1.1815242  2.1299555\n","\n","step: 384100\n","Step: 384100 -- Time: 4266 => ppl: 10.489224238102217\n","step: 384200\n","Step: 384200 -- Time: 4296 => ppl: 10.462437936492067\n","step: 384300\n","Step: 384300 -- Time: 4325 => ppl: 11.660500648489489\n","step: 384400\n","Step: 384400 -- Time: 4356 => ppl: 11.122986661906227\n","step: 384500\n","Step: 384500 -- Time: 4383 => ppl: 10.986818930914975\n","step: 384600\n","Step: 384600 -- Time: 4412 => ppl: 11.238911753615385\n","step: 384700\n","Step: 384700 -- Time: 4443 => ppl: 11.523938442156169\n","step: 384800\n","Step: 384800 -- Time: 4470 => ppl: 10.031981464168581\n","step: 384900\n","Step: 384900 -- Time: 4500 => ppl: 10.673449660059404\n","step: 385000\n","Step: 385000 -- Time: 4528 => ppl: 10.668383537529763\n","validation\n","### Step: 385000 -- Time: 4574 => ppl: 10.841085437831547\n","cnt 77\n","\n","1.2350847  2.606612\n","\n","step: 385100\n","Step: 385100 -- Time: 4608 => ppl: 10.387905814774848\n","step: 385200\n","Step: 385200 -- Time: 4639 => ppl: 10.77259395096155\n","step: 385300\n","Step: 385300 -- Time: 4670 => ppl: 10.873961062612862\n","step: 385400\n","Step: 385400 -- Time: 4700 => ppl: 11.316305671170994\n","step: 385500\n","Step: 385500 -- Time: 4728 => ppl: 10.737454312615533\n","step: 385600\n","Step: 385600 -- Time: 4757 => ppl: 10.85825743968487\n","step: 385700\n","Step: 385700 -- Time: 4785 => ppl: 10.30226448984228\n","step: 385800\n","Step: 385800 -- Time: 4813 => ppl: 10.77908733198567\n","step: 385900\n","Step: 385900 -- Time: 4844 => ppl: 10.919751766943978\n","step: 386000\n","Step: 386000 -- Time: 4872 => ppl: 10.404251622645841\n","\n","1.5001401  2.6375117\n","\n","step: 386100\n","Step: 386100 -- Time: 4903 => ppl: 10.513377603735847\n","step: 386200\n","Step: 386200 -- Time: 4932 => ppl: 10.922036489364956\n","step: 386300\n","Step: 386300 -- Time: 4961 => ppl: 10.825949236813456\n","step: 386400\n","Step: 386400 -- Time: 4990 => ppl: 10.578702769021328\n","step: 386500\n","Step: 386500 -- Time: 5020 => ppl: 10.743641996158624\n","step: 386600\n","Step: 386600 -- Time: 5047 => ppl: 10.53151251410582\n","step: 386700\n","Step: 386700 -- Time: 5078 => ppl: 11.080624138626685\n","step: 386800\n","Step: 386800 -- Time: 5108 => ppl: 11.012831769291342\n","step: 386900\n","Step: 386900 -- Time: 5138 => ppl: 10.356709268690974\n","step: 387000\n","Step: 387000 -- Time: 5168 => ppl: 10.7631746755508\n","\n","1.0399547  2.0912962\n","\n","step: 387100\n","Step: 387100 -- Time: 5194 => ppl: 11.41364589641391\n","step: 387200\n","Step: 387200 -- Time: 5223 => ppl: 10.863783813172411\n","step: 387300\n","Step: 387300 -- Time: 5250 => ppl: 10.610600813267013\n","step: 387400\n","Step: 387400 -- Time: 5278 => ppl: 10.62683428591867\n","step: 387500\n","Step: 387500 -- Time: 5306 => ppl: 10.882835410107962\n","step: 387600\n","Step: 387600 -- Time: 5334 => ppl: 10.822096675608753\n","step: 387700\n","Step: 387700 -- Time: 5362 => ppl: 10.28423947735068\n","step: 387800\n","Step: 387800 -- Time: 5392 => ppl: 10.376367399807119\n","step: 387900\n","Step: 387900 -- Time: 5420 => ppl: 9.833764125427416\n","step: 388000\n","Step: 388000 -- Time: 5450 => ppl: 11.081259061709575\n","\n","1.6687361  2.9674952\n","\n","step: 388100\n","Step: 388100 -- Time: 5478 => ppl: 10.107795183784349\n","step: 388200\n","Step: 388200 -- Time: 5509 => ppl: 10.373880523839265\n","step: 388300\n","Step: 388300 -- Time: 5538 => ppl: 9.532467077099382\n","step: 388400\n","Step: 388400 -- Time: 5566 => ppl: 10.243318484225384\n","step: 388500\n","Step: 388500 -- Time: 5596 => ppl: 10.950312561661656\n","step: 388600\n","Step: 388600 -- Time: 5627 => ppl: 11.614019915171422\n","step: 388700\n","Step: 388700 -- Time: 5657 => ppl: 10.819099289764129\n","step: 388800\n","Step: 388800 -- Time: 5689 => ppl: 11.022604817793457\n","step: 388900\n","Step: 388900 -- Time: 5719 => ppl: 10.418201982932835\n","step: 389000\n","Step: 389000 -- Time: 5748 => ppl: 10.948318267185453\n","\n","1.1785156  2.128493\n","\n","step: 389100\n","Step: 389100 -- Time: 5781 => ppl: 11.658709538928884\n","step: 389200\n","Step: 389200 -- Time: 5811 => ppl: 10.820152267892336\n","step: 389300\n","Step: 389300 -- Time: 5840 => ppl: 10.866078535728722\n","step: 389400\n","Step: 389400 -- Time: 5869 => ppl: 10.251431564101685\n","step: 389500\n","Step: 389500 -- Time: 5896 => ppl: 10.289340881328933\n","step: 389600\n","Step: 389600 -- Time: 5926 => ppl: 10.517948442871345\n","step: 389700\n","Step: 389700 -- Time: 5956 => ppl: 10.293733513167465\n","step: 389800\n","Step: 389800 -- Time: 5986 => ppl: 10.923693989639201\n","step: 389900\n","Step: 389900 -- Time: 6015 => ppl: 10.253241322704708\n","step: 390000\n","Step: 390000 -- Time: 6046 => ppl: 10.35743478215819\n","validation\n","### Step: 390000 -- Time: 6094 => ppl: 10.698733650441309\n","cnt 78\n","\n","1.3807693  2.2932262\n","\n","step: 390100\n","Step: 390100 -- Time: 6127 => ppl: 10.90540408893108\n","step: 390200\n","Step: 390200 -- Time: 6157 => ppl: 10.58746387883139\n","step: 390300\n","Step: 390300 -- Time: 6187 => ppl: 10.232968895536857\n","step: 390400\n","Step: 390400 -- Time: 6218 => ppl: 11.068734753118946\n","step: 390500\n","Step: 390500 -- Time: 6248 => ppl: 10.815883736706283\n","step: 390600\n","Step: 390600 -- Time: 6276 => ppl: 11.00018283045383\n","step: 390700\n","Step: 390700 -- Time: 6308 => ppl: 10.55797265944752\n","step: 390800\n","Step: 390800 -- Time: 6339 => ppl: 11.146261067633784\n","step: 390900\n","Step: 390900 -- Time: 6369 => ppl: 10.635946513032168\n","step: 391000\n","Step: 391000 -- Time: 6399 => ppl: 10.79781230117421\n","\n","1.2871914  2.7622533\n","\n","step: 391100\n","Step: 391100 -- Time: 6428 => ppl: 11.04701952626234\n","step: 391200\n","Step: 391200 -- Time: 6459 => ppl: 11.28154027488944\n","step: 391300\n","Step: 391300 -- Time: 6489 => ppl: 10.95739689464643\n","step: 391400\n","Step: 391400 -- Time: 6520 => ppl: 11.12155198493547\n","step: 391500\n","Step: 391500 -- Time: 6551 => ppl: 9.940826433270065\n","step: 391600\n","Step: 391600 -- Time: 6581 => ppl: 10.422240331984538\n","step: 391700\n","Step: 391700 -- Time: 6612 => ppl: 10.95577429338956\n","step: 391800\n","Step: 391800 -- Time: 6639 => ppl: 10.260465019260264\n","step: 391900\n","Step: 391900 -- Time: 6669 => ppl: 11.197362805879486\n","step: 392000\n","Step: 392000 -- Time: 6699 => ppl: 10.798368346201581\n","\n","2.0220275  3.091996\n","\n","step: 392100\n","Step: 392100 -- Time: 6727 => ppl: 9.804612316710703\n","step: 392200\n","Step: 392200 -- Time: 6755 => ppl: 10.672746677869732\n","step: 392300\n","Step: 392300 -- Time: 6786 => ppl: 11.02128074968259\n","step: 392400\n","Step: 392400 -- Time: 6816 => ppl: 11.209696746994727\n","step: 392500\n","Step: 392500 -- Time: 6847 => ppl: 11.03219229679361\n","step: 392600\n","Step: 392600 -- Time: 6876 => ppl: 10.642336343187802\n","step: 392700\n","Step: 392700 -- Time: 6906 => ppl: 10.859905548165765\n","step: 392800\n","Step: 392800 -- Time: 6933 => ppl: 9.858607903832246\n","step: 392900\n","Step: 392900 -- Time: 6963 => ppl: 10.614839709118133\n","step: 393000\n","Step: 393000 -- Time: 6989 => ppl: 9.83436671388124\n","\n","1.8627136  3.4052193\n","\n","step: 393100\n","Step: 393100 -- Time: 7018 => ppl: 10.768811506034567\n","step: 393200\n","Step: 393200 -- Time: 7048 => ppl: 10.805167276149787\n","step: 393300\n","Step: 393300 -- Time: 7078 => ppl: 10.70737100086091\n","step: 393400\n","Step: 393400 -- Time: 7107 => ppl: 10.953255168426896\n","step: 393500\n","Step: 393500 -- Time: 7135 => ppl: 9.651224910026533\n","step: 393600\n","Step: 393600 -- Time: 7164 => ppl: 11.398692079582082\n","step: 393700\n","Step: 393700 -- Time: 7194 => ppl: 10.593691439821741\n","step: 393800\n","Step: 393800 -- Time: 7223 => ppl: 10.43759313815996\n","step: 393900\n","Step: 393900 -- Time: 7252 => ppl: 10.67026912548266\n","step: 394000\n","Step: 394000 -- Time: 7280 => ppl: 10.138258871197154\n","\n","1.0893468  1.8464469\n","\n","step: 394100\n","Step: 394100 -- Time: 7307 => ppl: 10.240136823356258\n","step: 394200\n","Step: 394200 -- Time: 7338 => ppl: 10.764985255548384\n","step: 394300\n","Step: 394300 -- Time: 7365 => ppl: 9.785614427550318\n","step: 394400\n","Step: 394400 -- Time: 7395 => ppl: 10.941515187057268\n","step: 394500\n","Step: 394500 -- Time: 7424 => ppl: 10.367877178222258\n","step: 394600\n","Step: 394600 -- Time: 7454 => ppl: 10.68935596004785\n","step: 394700\n","Step: 394700 -- Time: 7485 => ppl: 11.119243884113612\n","step: 394800\n","Step: 394800 -- Time: 7515 => ppl: 11.224289351900955\n","step: 394900\n","Step: 394900 -- Time: 7544 => ppl: 11.144411757488085\n","step: 395000\n","Step: 395000 -- Time: 7573 => ppl: 10.327644788675881\n","validation\n","### Step: 395000 -- Time: 7619 => ppl: 10.575654108916055\n","cnt 79\n","\n","2.0865266  3.3388324\n","\n","step: 395100\n","Step: 395100 -- Time: 7652 => ppl: 10.03275019310786\n","step: 395200\n","Step: 395200 -- Time: 7683 => ppl: 10.621523067171474\n","step: 395300\n","Step: 395300 -- Time: 7712 => ppl: 10.210453037578239\n","step: 395400\n","Step: 395400 -- Time: 7740 => ppl: 11.109748616403435\n","step: 395500\n","Step: 395500 -- Time: 7770 => ppl: 10.296298487537817\n","step: 395600\n","Step: 395600 -- Time: 7801 => ppl: 11.116890075802292\n","step: 395700\n","Step: 395700 -- Time: 7833 => ppl: 10.858760106089706\n","step: 395800\n","Step: 395800 -- Time: 7861 => ppl: 11.284542080288166\n","step: 395900\n","Step: 395900 -- Time: 7890 => ppl: 10.721610018368034\n","step: 396000\n","Step: 396000 -- Time: 7919 => ppl: 12.175635312389346\n","\n","0.9106874  1.5805327\n","\n","step: 396100\n","Step: 396100 -- Time: 7950 => ppl: 10.28415109186109\n","step: 396200\n","Step: 396200 -- Time: 7978 => ppl: 10.094129452608591\n","step: 396300\n","Step: 396300 -- Time: 8005 => ppl: 10.373908622546548\n","step: 396400\n","Step: 396400 -- Time: 8033 => ppl: 10.032307408059893\n","step: 396500\n","Step: 396500 -- Time: 8063 => ppl: 10.553699274932383\n","step: 396600\n","Step: 396600 -- Time: 8090 => ppl: 9.53542246368327\n","step: 396700\n","Step: 396700 -- Time: 8119 => ppl: 10.890040640984457\n","step: 396800\n","Step: 396800 -- Time: 8147 => ppl: 10.27598158375715\n","step: 396900\n","Step: 396900 -- Time: 8176 => ppl: 10.79122128114299\n","step: 397000\n","Step: 397000 -- Time: 8205 => ppl: 11.369756745911591\n","\n","1.2303507  2.1332328\n","\n","step: 397100\n","Step: 397100 -- Time: 8234 => ppl: 11.543542321941368\n","step: 397200\n","Step: 397200 -- Time: 8265 => ppl: 10.564149755355384\n","step: 397300\n","Step: 397300 -- Time: 8293 => ppl: 10.686674675063486\n","step: 397400\n","Step: 397400 -- Time: 8321 => ppl: 10.972232902237774\n","step: 397500\n","Step: 397500 -- Time: 8352 => ppl: 11.507200899804431\n","step: 397600\n","Step: 397600 -- Time: 8381 => ppl: 10.560108495354378\n","step: 397700\n","Step: 397700 -- Time: 8412 => ppl: 10.440123962500373\n","step: 397800\n","Step: 397800 -- Time: 8441 => ppl: 10.840727066885162\n","step: 397900\n","Step: 397900 -- Time: 8471 => ppl: 11.892539727495793\n","step: 398000\n","Step: 398000 -- Time: 8501 => ppl: 10.164566561699996\n","\n","5.9554057  7.3167396\n","\n","step: 398100\n","Step: 398100 -- Time: 8529 => ppl: 10.747477160641346\n","step: 398200\n","Step: 398200 -- Time: 8557 => ppl: 10.681767149323052\n","step: 398300\n","Step: 398300 -- Time: 8587 => ppl: 10.524868756437424\n","step: 398400\n","Step: 398400 -- Time: 8616 => ppl: 10.489490081898179\n","step: 398500\n","Step: 398500 -- Time: 8645 => ppl: 10.746535006273682\n","step: 398600\n","Step: 398600 -- Time: 8673 => ppl: 10.424353274987817\n","step: 398700\n","Step: 398700 -- Time: 8703 => ppl: 10.506421959568511\n","step: 398800\n","Step: 398800 -- Time: 8732 => ppl: 10.699984844439571\n","step: 398900\n","Step: 398900 -- Time: 8759 => ppl: 10.99429075688146\n","step: 399000\n","Step: 399000 -- Time: 8788 => ppl: 10.671393767443769\n","\n","1.0652587  1.7790278\n","\n","step: 399100\n","Step: 399100 -- Time: 8816 => ppl: 10.629425294738763\n","step: 399200\n","Step: 399200 -- Time: 8846 => ppl: 10.540996715939164\n","step: 399300\n","Step: 399300 -- Time: 8875 => ppl: 11.315375996295465\n","step: 399400\n","Step: 399400 -- Time: 8907 => ppl: 10.310505950524632\n","step: 399500\n","Step: 399500 -- Time: 8935 => ppl: 10.110764290023704\n","step: 399600\n","Step: 399600 -- Time: 8967 => ppl: 10.742563975563456\n","step: 399700\n","Step: 399700 -- Time: 8996 => ppl: 11.212859780669362\n","step: 399800\n","Step: 399800 -- Time: 9025 => ppl: 10.813787345258309\n","step: 399900\n","Step: 399900 -- Time: 9054 => ppl: 10.883276102619236\n","step: 400000\n","Step: 400000 -- Time: 9084 => ppl: 10.527583376018947\n","validation\n","### Step: 400000 -- Time: 9130 => ppl: 10.82334504324981\n","cnt 80\n","\n","2.2554393  4.3118844\n","\n","step: 400100\n","Step: 400100 -- Time: 9165 => ppl: 11.740681489861672\n","step: 400200\n","Step: 400200 -- Time: 9194 => ppl: 9.800741806606204\n","step: 400300\n","Step: 400300 -- Time: 9224 => ppl: 10.800720844084964\n","step: 400400\n","Step: 400400 -- Time: 9252 => ppl: 10.354384306926674\n","step: 400500\n","Step: 400500 -- Time: 9282 => ppl: 10.942329208280961\n","step: 400600\n","Step: 400600 -- Time: 9311 => ppl: 10.846959474895964\n","step: 400700\n","Step: 400700 -- Time: 9342 => ppl: 10.470599893556496\n","step: 400800\n","Step: 400800 -- Time: 9369 => ppl: 10.786509607273018\n","step: 400900\n","Step: 400900 -- Time: 9396 => ppl: 10.802843623741904\n","step: 401000\n","Step: 401000 -- Time: 9425 => ppl: 11.046687742841987\n","\n","1.6558636  3.346365\n","\n","step: 401100\n","Step: 401100 -- Time: 9456 => ppl: 10.681601533920379\n","step: 401200\n","Step: 401200 -- Time: 9485 => ppl: 10.843929038737302\n","step: 401300\n","Step: 401300 -- Time: 9512 => ppl: 10.537105361680423\n","step: 401400\n","Step: 401400 -- Time: 9542 => ppl: 10.444108241915984\n","step: 401500\n","Step: 401500 -- Time: 9572 => ppl: 10.659408216600665\n","step: 401600\n","Step: 401600 -- Time: 9601 => ppl: 10.858284392005364\n","step: 401700\n","Step: 401700 -- Time: 9632 => ppl: 11.302416978673234\n","step: 401800\n","Step: 401800 -- Time: 9659 => ppl: 10.663532247502541\n","step: 401900\n","Step: 401900 -- Time: 9688 => ppl: 10.637450611176694\n","step: 402000\n","Step: 402000 -- Time: 9719 => ppl: 10.771149287611562\n","\n","0.9109714  1.8251269\n","\n","step: 402100\n","Step: 402100 -- Time: 9747 => ppl: 11.040312815663558\n","step: 402200\n","Step: 402200 -- Time: 9776 => ppl: 10.994280482275368\n","step: 402300\n","Step: 402300 -- Time: 9805 => ppl: 10.476180216168078\n","step: 402400\n","Step: 402400 -- Time: 9832 => ppl: 10.819059847541567\n","step: 402500\n","Step: 402500 -- Time: 9861 => ppl: 10.878438994473138\n","step: 402600\n","Step: 402600 -- Time: 9891 => ppl: 10.488234368975258\n","step: 402700\n","Step: 402700 -- Time: 9920 => ppl: 10.591371257524038\n","step: 402800\n","Step: 402800 -- Time: 9948 => ppl: 10.432525571526423\n","step: 402900\n","Step: 402900 -- Time: 9977 => ppl: 10.436655597935866\n","step: 403000\n","Step: 403000 -- Time: 10009 => ppl: 10.607811170187503\n","\n","1.850963  3.9719825\n","\n","step: 403100\n","Step: 403100 -- Time: 10037 => ppl: 10.457167570575555\n","step: 403200\n","Step: 403200 -- Time: 10064 => ppl: 10.723074193303786\n","step: 403300\n","Step: 403300 -- Time: 10094 => ppl: 10.493149455529036\n","step: 403400\n","Step: 403400 -- Time: 10124 => ppl: 10.551114397202639\n","step: 403500\n","Step: 403500 -- Time: 10153 => ppl: 10.62573210193491\n","step: 403600\n","Step: 403600 -- Time: 10183 => ppl: 10.585177842253284\n","step: 403700\n","Step: 403700 -- Time: 10212 => ppl: 10.98755573737693\n","step: 403800\n","Step: 403800 -- Time: 10240 => ppl: 10.30138848325989\n","step: 403900\n","Step: 403900 -- Time: 10267 => ppl: 11.121931562452094\n","step: 404000\n","Step: 404000 -- Time: 10298 => ppl: 10.81531359925011\n","\n","1.2746835  2.0261614\n","\n","step: 404100\n","Step: 404100 -- Time: 10329 => ppl: 9.829893689767783\n","step: 404200\n","Step: 404200 -- Time: 10358 => ppl: 11.05554165332199\n","step: 404300\n","Step: 404300 -- Time: 10386 => ppl: 10.63326553362801\n","step: 404400\n","Step: 404400 -- Time: 10415 => ppl: 10.219308511365709\n","step: 404500\n","Step: 404500 -- Time: 10443 => ppl: 10.564116305447765\n","step: 404600\n","Step: 404600 -- Time: 10472 => ppl: 10.954022969250488\n","step: 404700\n","Step: 404700 -- Time: 10501 => ppl: 10.953480830085912\n","step: 404800\n","Step: 404800 -- Time: 10529 => ppl: 10.573124160207929\n","step: 404900\n","Step: 404900 -- Time: 10558 => ppl: 10.821794717810334\n","step: 405000\n","Step: 405000 -- Time: 10589 => ppl: 10.722799718370121\n","validation\n","### Step: 405000 -- Time: 10637 => ppl: 10.6569077254431\n","cnt 81\n","\n","0.89680016  1.6170166\n","\n","step: 405100\n","Step: 405100 -- Time: 10669 => ppl: 10.881617074424124\n","step: 405200\n","Step: 405200 -- Time: 10698 => ppl: 11.22201573257509\n","step: 405300\n","Step: 405300 -- Time: 10728 => ppl: 10.949226560359426\n","step: 405400\n","Step: 405400 -- Time: 10758 => ppl: 10.743869491500593\n","step: 405500\n","Step: 405500 -- Time: 10786 => ppl: 9.922697674144766\n","step: 405600\n","Step: 405600 -- Time: 10815 => ppl: 10.995400588970034\n","step: 405700\n","Step: 405700 -- Time: 10845 => ppl: 10.50868497005155\n","step: 405800\n","Step: 405800 -- Time: 10877 => ppl: 10.760000816324087\n","step: 405900\n","Step: 405900 -- Time: 10906 => ppl: 10.736395738071678\n","step: 406000\n","Step: 406000 -- Time: 10936 => ppl: 11.128941747464552\n","\n","3.3913407  4.5506825\n","\n","step: 406100\n","Step: 406100 -- Time: 10966 => ppl: 10.325505921363062\n","step: 406200\n","Step: 406200 -- Time: 10995 => ppl: 10.336562656031893\n","step: 406300\n","Step: 406300 -- Time: 11025 => ppl: 11.17435405029159\n","step: 406400\n","Step: 406400 -- Time: 11054 => ppl: 10.692539188788864\n","step: 406500\n","Step: 406500 -- Time: 11082 => ppl: 10.58798333522158\n","step: 406600\n","Step: 406600 -- Time: 11110 => ppl: 10.362965693780986\n","step: 406700\n","Step: 406700 -- Time: 11140 => ppl: 10.451751885195545\n","step: 406800\n","Step: 406800 -- Time: 11169 => ppl: 10.176913473293293\n","step: 406900\n","Step: 406900 -- Time: 11199 => ppl: 10.506999185188537\n","step: 407000\n","Step: 407000 -- Time: 11230 => ppl: 11.247766658534092\n","\n","2.2114356  3.6288064\n","\n","step: 407100\n","Step: 407100 -- Time: 11263 => ppl: 11.624618837013493\n","step: 407200\n","Step: 407200 -- Time: 11293 => ppl: 10.766633743562881\n","step: 407300\n","Step: 407300 -- Time: 11323 => ppl: 10.255213826084164\n","step: 407400\n","Step: 407400 -- Time: 11352 => ppl: 10.292472233744673\n","step: 407500\n","Step: 407500 -- Time: 11382 => ppl: 11.056556998558651\n","step: 407600\n","Step: 407600 -- Time: 11409 => ppl: 10.324781808366176\n","step: 407700\n","Step: 407700 -- Time: 11438 => ppl: 11.25998396503264\n","step: 407800\n","Step: 407800 -- Time: 11468 => ppl: 10.277965833483487\n","step: 407900\n","Step: 407900 -- Time: 11499 => ppl: 11.61468223492773\n","step: 408000\n","Step: 408000 -- Time: 11528 => ppl: 10.589868433368826\n","\n","0.93419987  1.8360738\n","\n","step: 408100\n","Step: 408100 -- Time: 11557 => ppl: 10.793228911638826\n","step: 408200\n","Step: 408200 -- Time: 11587 => ppl: 10.881689662519424\n","step: 408300\n","Step: 408300 -- Time: 11616 => ppl: 10.863362814134844\n","step: 408400\n","Step: 408400 -- Time: 11645 => ppl: 10.63595129394365\n","step: 408500\n","Step: 408500 -- Time: 11674 => ppl: 10.411279696028426\n","step: 408600\n","Step: 408600 -- Time: 11704 => ppl: 10.906054817169995\n","step: 408700\n","Step: 408700 -- Time: 11734 => ppl: 10.909346919071657\n","step: 408800\n","Step: 408800 -- Time: 11760 => ppl: 10.671838542921096\n","step: 408900\n","Step: 408900 -- Time: 11792 => ppl: 10.821245335039775\n","step: 409000\n","Step: 409000 -- Time: 11823 => ppl: 10.413571096658458\n","\n","1.0712306  1.8695846\n","\n","step: 409100\n","Step: 409100 -- Time: 11851 => ppl: 10.52652831342707\n","step: 409200\n","Step: 409200 -- Time: 11880 => ppl: 10.172210629631918\n","step: 409300\n","Step: 409300 -- Time: 11909 => ppl: 10.234476403614268\n","step: 409400\n","Step: 409400 -- Time: 11938 => ppl: 10.80959921114376\n","step: 409500\n","Step: 409500 -- Time: 11966 => ppl: 10.816096013254674\n","step: 409600\n","Step: 409600 -- Time: 11995 => ppl: 10.426077963655615\n","step: 409700\n","Step: 409700 -- Time: 12025 => ppl: 10.928593951528581\n","step: 409800\n","Step: 409800 -- Time: 12053 => ppl: 10.860458616671577\n","step: 409900\n","Step: 409900 -- Time: 12081 => ppl: 10.622929711765552\n","step: 410000\n","Step: 410000 -- Time: 12112 => ppl: 11.000377963535305\n","validation\n","### Step: 410000 -- Time: 12156 => ppl: 10.609761344783042\n","cnt 82\n","\n","1.3857157  2.3236678\n","\n","step: 410100\n","Step: 410100 -- Time: 12188 => ppl: 10.05055475500267\n","step: 410200\n","Step: 410200 -- Time: 12216 => ppl: 10.408306460641\n","step: 410300\n","Step: 410300 -- Time: 12245 => ppl: 10.177021262235503\n","step: 410400\n","Step: 410400 -- Time: 12274 => ppl: 11.268009748831787\n","step: 410500\n","Step: 410500 -- Time: 12306 => ppl: 11.064178489115525\n","step: 410600\n","Step: 410600 -- Time: 12336 => ppl: 10.55621966308563\n","step: 410700\n","Step: 410700 -- Time: 12366 => ppl: 10.286501047985013\n","step: 410800\n","Step: 410800 -- Time: 12396 => ppl: 11.278418805952299\n","step: 410900\n","Step: 410900 -- Time: 12425 => ppl: 10.313607900122484\n","step: 411000\n","Step: 411000 -- Time: 12455 => ppl: 10.724807903443468\n","\n","2.1949837  3.7186034\n","\n","step: 411100\n","Step: 411100 -- Time: 12485 => ppl: 10.527652836950526\n","step: 411200\n","Step: 411200 -- Time: 12516 => ppl: 10.881771854083665\n","step: 411300\n","Step: 411300 -- Time: 12547 => ppl: 10.222028352611003\n","step: 411400\n","Step: 411400 -- Time: 12574 => ppl: 10.243016323477121\n","step: 411500\n","Step: 411500 -- Time: 12603 => ppl: 10.565171215692207\n","step: 411600\n","Step: 411600 -- Time: 12634 => ppl: 10.403984680942415\n","step: 411700\n","Step: 411700 -- Time: 12663 => ppl: 10.874192665240491\n","step: 411800\n","Step: 411800 -- Time: 12694 => ppl: 11.308782684779267\n","step: 411900\n","Step: 411900 -- Time: 12722 => ppl: 10.719716473815621\n","step: 412000\n","Step: 412000 -- Time: 12751 => ppl: 10.534467559152533\n","\n","2.681437  3.8731046\n","\n","step: 412100\n","Step: 412100 -- Time: 12780 => ppl: 11.524144446888759\n","step: 412200\n","Step: 412200 -- Time: 12809 => ppl: 10.25525551746375\n","step: 412300\n","Step: 412300 -- Time: 12837 => ppl: 10.1988551660325\n","step: 412400\n","Step: 412400 -- Time: 12864 => ppl: 10.467460041811265\n","step: 412500\n","Step: 412500 -- Time: 12891 => ppl: 10.634607573289482\n","step: 412600\n","Step: 412600 -- Time: 12921 => ppl: 10.418797614631261\n","step: 412700\n","Step: 412700 -- Time: 12951 => ppl: 10.3788045309164\n","step: 412800\n","Step: 412800 -- Time: 12979 => ppl: 10.84674971161443\n","step: 412900\n","Step: 412900 -- Time: 13007 => ppl: 10.557110884688832\n","step: 413000\n","Step: 413000 -- Time: 13037 => ppl: 10.736131443413418\n","\n","1.3813788  2.8935776\n","\n","step: 413100\n","Step: 413100 -- Time: 13069 => ppl: 10.819002830004385\n","step: 413200\n","Step: 413200 -- Time: 13097 => ppl: 10.405656465603384\n","step: 413300\n","Step: 413300 -- Time: 13128 => ppl: 10.919172653576782\n","step: 413400\n","Step: 413400 -- Time: 13154 => ppl: 10.64501213308487\n","step: 413500\n","Step: 413500 -- Time: 13186 => ppl: 11.059362266811858\n","step: 413600\n","Step: 413600 -- Time: 13215 => ppl: 10.958352011932446\n","step: 413700\n","Step: 413700 -- Time: 13245 => ppl: 10.523506383139518\n","step: 413800\n","Step: 413800 -- Time: 13275 => ppl: 10.621963956038039\n","step: 413900\n","Step: 413900 -- Time: 13304 => ppl: 11.046517364043593\n","step: 414000\n","Step: 414000 -- Time: 13334 => ppl: 10.95051687186947\n","\n","1.6269802  2.6603315\n","\n","step: 414100\n","Step: 414100 -- Time: 13364 => ppl: 10.538535858566803\n","step: 414200\n","Step: 414200 -- Time: 13392 => ppl: 10.356860501569853\n","step: 414300\n","Step: 414300 -- Time: 13422 => ppl: 11.116943326243765\n","step: 414400\n","Step: 414400 -- Time: 13451 => ppl: 10.091616768042933\n","step: 414500\n","Step: 414500 -- Time: 13478 => ppl: 10.131944068868593\n","step: 414600\n","Step: 414600 -- Time: 13507 => ppl: 11.070833988779738\n","step: 414700\n","Step: 414700 -- Time: 13537 => ppl: 10.45886344818711\n","step: 414800\n","Step: 414800 -- Time: 13566 => ppl: 11.221819319860924\n","step: 414900\n","Step: 414900 -- Time: 13595 => ppl: 10.872747493737894\n","step: 415000\n","Step: 415000 -- Time: 13624 => ppl: 11.008078929809548\n","validation\n","### Step: 415000 -- Time: 13669 => ppl: 10.67688882920935\n","cnt 83\n","\n","1.5945404  3.479904\n","\n","step: 415100\n","Step: 415100 -- Time: 13701 => ppl: 10.685769248849189\n","step: 415200\n","Step: 415200 -- Time: 13733 => ppl: 11.710123733556598\n","step: 415300\n","Step: 415300 -- Time: 13761 => ppl: 10.393710849369059\n","step: 415400\n","Step: 415400 -- Time: 13791 => ppl: 10.489001805382339\n","step: 415500\n","Step: 415500 -- Time: 13821 => ppl: 10.888510769322385\n","step: 415600\n","Step: 415600 -- Time: 13851 => ppl: 10.71321594215361\n","step: 415700\n","Step: 415700 -- Time: 13879 => ppl: 10.095563777606081\n","step: 415800\n","Step: 415800 -- Time: 13909 => ppl: 10.79912911785962\n","step: 415900\n","Step: 415900 -- Time: 13939 => ppl: 10.816983737573658\n","step: 416000\n","Step: 416000 -- Time: 13969 => ppl: 11.05741011338595\n","\n","2.1810596  2.9581347\n","\n","step: 416100\n","Step: 416100 -- Time: 13997 => ppl: 9.863275174758362\n","step: 416200\n","Step: 416200 -- Time: 14028 => ppl: 11.222089905185896\n","step: 416300\n","Step: 416300 -- Time: 14057 => ppl: 10.825301803355927\n","step: 416400\n","Step: 416400 -- Time: 14086 => ppl: 10.34717342842408\n","step: 416500\n","Step: 416500 -- Time: 14115 => ppl: 10.638484705887846\n","step: 416600\n","Step: 416600 -- Time: 14141 => ppl: 10.501366218789155\n","step: 416700\n","Step: 416700 -- Time: 14171 => ppl: 11.070919484298692\n","step: 416800\n","Step: 416800 -- Time: 14201 => ppl: 10.705179321057816\n","step: 416900\n","Step: 416900 -- Time: 14231 => ppl: 10.437183471940347\n","step: 417000\n","Step: 417000 -- Time: 14262 => ppl: 11.0296690798515\n","\n","1.8497345  3.4173543\n","\n","step: 417100\n","Step: 417100 -- Time: 14292 => ppl: 10.494151165241433\n","step: 417200\n","Step: 417200 -- Time: 14322 => ppl: 10.830933851005836\n","step: 417300\n","Step: 417300 -- Time: 14353 => ppl: 10.354820361668812\n","step: 417400\n","Step: 417400 -- Time: 14382 => ppl: 10.428428209115166\n","step: 417500\n","Step: 417500 -- Time: 14411 => ppl: 10.451010611273375\n","step: 417600\n","Step: 417600 -- Time: 14444 => ppl: 11.674306264087733\n","step: 417700\n","Step: 417700 -- Time: 14476 => ppl: 10.634841336461493\n","step: 417800\n","Step: 417800 -- Time: 14507 => ppl: 10.660450770503402\n","step: 417900\n","Step: 417900 -- Time: 14536 => ppl: 10.621531115243556\n","step: 418000\n","Step: 418000 -- Time: 14565 => ppl: 10.061831602143942\n","\n","1.4077661  2.2918892\n","\n","step: 418100\n","Step: 418100 -- Time: 14597 => ppl: 11.269760968650715\n","step: 418200\n","Step: 418200 -- Time: 14626 => ppl: 10.49532240745983\n","step: 418300\n","Step: 418300 -- Time: 14656 => ppl: 10.727833726280368\n","step: 418400\n","Step: 418400 -- Time: 14686 => ppl: 10.853286213027634\n","step: 418500\n","Step: 418500 -- Time: 14717 => ppl: 10.844516437715585\n","step: 418600\n","Step: 418600 -- Time: 14746 => ppl: 10.381366933245532\n","step: 418700\n","Step: 418700 -- Time: 14775 => ppl: 10.577213925839674\n","step: 418800\n","Step: 418800 -- Time: 14804 => ppl: 10.86375322960109\n","step: 418900\n","Step: 418900 -- Time: 14834 => ppl: 10.614800450204658\n","step: 419000\n","Step: 419000 -- Time: 14867 => ppl: 10.642605627831392\n","\n","1.2342134  2.9807117\n","\n","step: 419100\n","Step: 419100 -- Time: 14894 => ppl: 10.418204513837095\n","step: 419200\n","Step: 419200 -- Time: 14927 => ppl: 10.66417546923112\n","step: 419300\n","Step: 419300 -- Time: 14957 => ppl: 10.513781729501977\n","step: 419400\n","Step: 419400 -- Time: 14987 => ppl: 10.889899016163884\n","step: 419500\n","Step: 419500 -- Time: 15016 => ppl: 10.828860446437844\n","step: 419600\n","Step: 419600 -- Time: 15046 => ppl: 10.638593709087026\n","step: 419700\n","Step: 419700 -- Time: 15076 => ppl: 11.002548711615338\n","step: 419800\n","Step: 419800 -- Time: 15106 => ppl: 10.746272575364717\n","step: 419900\n","Step: 419900 -- Time: 15136 => ppl: 11.19040085015845\n","step: 420000\n","Step: 420000 -- Time: 15171 => ppl: 10.645127800181342\n","validation\n","### Step: 420000 -- Time: 15217 => ppl: 10.50886647132775\n","cnt 84\n","\n","2.3086991  4.62769\n","\n","step: 420100\n","Step: 420100 -- Time: 15249 => ppl: 10.741754679020266\n","step: 420200\n","Step: 420200 -- Time: 15279 => ppl: 10.261487538649254\n","step: 420300\n","Step: 420300 -- Time: 15307 => ppl: 10.932678158162668\n","step: 420400\n","Step: 420400 -- Time: 15334 => ppl: 10.140819359259293\n","step: 420500\n","Step: 420500 -- Time: 15364 => ppl: 10.89444823577907\n","step: 420600\n","Step: 420600 -- Time: 15393 => ppl: 10.90920809899783\n","step: 420700\n","Step: 420700 -- Time: 15424 => ppl: 9.983938061348178\n","step: 420800\n","Step: 420800 -- Time: 15452 => ppl: 9.896916041810336\n","step: 420900\n","Step: 420900 -- Time: 15484 => ppl: 10.141781207985547\n","step: 421000\n","Step: 421000 -- Time: 15512 => ppl: 10.695462511220281\n","\n","2.2731183  3.784791\n","\n","step: 421100\n","Step: 421100 -- Time: 15540 => ppl: 10.43620247204115\n","step: 421200\n","Step: 421200 -- Time: 15569 => ppl: 10.7939655252696\n","step: 421300\n","Step: 421300 -- Time: 15598 => ppl: 10.204365974649358\n","step: 421400\n","Step: 421400 -- Time: 15626 => ppl: 10.582624228219018\n","step: 421500\n","Step: 421500 -- Time: 15654 => ppl: 10.671659475354446\n","step: 421600\n","Step: 421600 -- Time: 15684 => ppl: 10.736919644813883\n","step: 421700\n","Step: 421700 -- Time: 15714 => ppl: 10.621642305644377\n","step: 421800\n","Step: 421800 -- Time: 15744 => ppl: 11.09474102451208\n","step: 421900\n","Step: 421900 -- Time: 15774 => ppl: 10.488537289480696\n","step: 422000\n","Step: 422000 -- Time: 15804 => ppl: 10.823515260340564\n","\n","1.409179  2.2292192\n","\n","step: 422100\n","Step: 422100 -- Time: 15832 => ppl: 10.831136775127506\n","step: 422200\n","Step: 422200 -- Time: 15860 => ppl: 10.628646178947031\n","step: 422300\n","Step: 422300 -- Time: 15888 => ppl: 10.833905412539362\n","step: 422400\n","Step: 422400 -- Time: 15919 => ppl: 10.870732294003293\n","step: 422500\n","Step: 422500 -- Time: 15950 => ppl: 10.61680013796562\n","step: 422600\n","Step: 422600 -- Time: 15979 => ppl: 10.817144516026069\n","step: 422700\n","Step: 422700 -- Time: 16008 => ppl: 10.683605172510534\n","step: 422800\n","Step: 422800 -- Time: 16037 => ppl: 10.745800510667856\n","step: 422900\n","Step: 422900 -- Time: 16065 => ppl: 10.73891549577822\n","step: 423000\n","Step: 423000 -- Time: 16093 => ppl: 10.548145583125596\n","\n","1.3700815  2.4421773\n","\n","step: 423100\n","Step: 423100 -- Time: 16121 => ppl: 10.313620708833506\n","step: 423200\n","Step: 423200 -- Time: 16150 => ppl: 9.834535218055647\n","step: 423300\n","Step: 423300 -- Time: 16181 => ppl: 9.863985862591077\n","step: 423400\n","Step: 423400 -- Time: 16210 => ppl: 10.998790412622832\n","step: 423500\n","Step: 423500 -- Time: 16243 => ppl: 11.152166034809987\n","step: 423600\n","Step: 423600 -- Time: 16270 => ppl: 10.197127207711313\n","step: 423700\n","Step: 423700 -- Time: 16299 => ppl: 9.97282803434289\n","step: 423800\n","Step: 423800 -- Time: 16330 => ppl: 10.342463033663883\n","step: 423900\n","Step: 423900 -- Time: 16361 => ppl: 10.818610831396246\n","step: 424000\n","Step: 424000 -- Time: 16389 => ppl: 10.307130248359917\n","\n","1.829631  3.228182\n","\n","step: 424100\n","Step: 424100 -- Time: 16420 => ppl: 10.920738254023453\n","step: 424200\n","Step: 424200 -- Time: 16447 => ppl: 10.516391263927355\n","step: 424300\n","Step: 424300 -- Time: 16477 => ppl: 9.910075610726611\n","step: 424400\n","Step: 424400 -- Time: 16507 => ppl: 10.323545062256315\n","step: 424500\n","Step: 424500 -- Time: 16535 => ppl: 11.22252830231107\n","step: 424600\n","Step: 424600 -- Time: 16566 => ppl: 11.080572380594594\n","step: 424700\n","Step: 424700 -- Time: 16595 => ppl: 9.921853696362547\n","step: 424800\n","Step: 424800 -- Time: 16626 => ppl: 10.50279202001059\n","step: 424900\n","Step: 424900 -- Time: 16655 => ppl: 10.47186869824311\n","step: 425000\n","Step: 425000 -- Time: 16683 => ppl: 10.120448570252393\n","validation\n","### Step: 425000 -- Time: 16729 => ppl: 10.688750926677631\n","cnt 85\n","\n","1.6060547  3.2919524\n","\n","step: 425100\n","Step: 425100 -- Time: 16762 => ppl: 11.10369033409393\n","step: 425200\n","Step: 425200 -- Time: 16790 => ppl: 10.712379832140904\n","step: 425300\n","Step: 425300 -- Time: 16820 => ppl: 10.429284675990289\n","step: 425400\n","Step: 425400 -- Time: 16850 => ppl: 10.521906170883664\n","step: 425500\n","Step: 425500 -- Time: 16878 => ppl: 10.327285168180948\n","step: 425600\n","Step: 425600 -- Time: 16906 => ppl: 10.76220183450932\n","step: 425700\n","Step: 425700 -- Time: 16934 => ppl: 10.32573138840813\n","step: 425800\n","Step: 425800 -- Time: 16963 => ppl: 11.247559181578312\n","step: 425900\n","Step: 425900 -- Time: 16991 => ppl: 9.811221422088094\n","step: 426000\n","Step: 426000 -- Time: 17022 => ppl: 11.066984410847855\n","\n","2.6773913  4.652231\n","\n","step: 426100\n","Step: 426100 -- Time: 17054 => ppl: 10.649607220763606\n","step: 426200\n","Step: 426200 -- Time: 17084 => ppl: 9.956041442261997\n","step: 426300\n","Step: 426300 -- Time: 17113 => ppl: 10.847041036658736\n","step: 426400\n","Step: 426400 -- Time: 17142 => ppl: 10.919685574817553\n","step: 426500\n","Step: 426500 -- Time: 17173 => ppl: 10.448649983993548\n","step: 426600\n","Step: 426600 -- Time: 17203 => ppl: 10.905892771286162\n","step: 426700\n","Step: 426700 -- Time: 17232 => ppl: 10.950162995976743\n","step: 426800\n","Step: 426800 -- Time: 17257 => ppl: 10.695065859853603\n","step: 426900\n","Step: 426900 -- Time: 17288 => ppl: 10.925749250758606\n","step: 427000\n","Step: 427000 -- Time: 17318 => ppl: 10.661163055840513\n","\n","1.0606258  1.6500802\n","\n","step: 427100\n","Step: 427100 -- Time: 17347 => ppl: 11.499013547520455\n","step: 427200\n","Step: 427200 -- Time: 17378 => ppl: 11.106474669756828\n","step: 427300\n","Step: 427300 -- Time: 17408 => ppl: 10.051229711497346\n","step: 427400\n","Step: 427400 -- Time: 17437 => ppl: 11.110192521219453\n","step: 427500\n","Step: 427500 -- Time: 17466 => ppl: 10.570934558646831\n","step: 427600\n","Step: 427600 -- Time: 17498 => ppl: 10.68721316366045\n","step: 427700\n","Step: 427700 -- Time: 17528 => ppl: 10.714316736163168\n","step: 427800\n","Step: 427800 -- Time: 17561 => ppl: 11.234207723332737\n","step: 427900\n","Step: 427900 -- Time: 17589 => ppl: 10.684984043128571\n","step: 428000\n","Step: 428000 -- Time: 17619 => ppl: 11.33651640948328\n","\n","2.3179238  3.8122764\n","\n","step: 428100\n","Step: 428100 -- Time: 17647 => ppl: 10.050297668718404\n","step: 428200\n","Step: 428200 -- Time: 17675 => ppl: 10.462541210994052\n","step: 428300\n","Step: 428300 -- Time: 17704 => ppl: 10.435731102287418\n","step: 428400\n","Step: 428400 -- Time: 17733 => ppl: 9.802200518335953\n","step: 428500\n","Step: 428500 -- Time: 17763 => ppl: 11.006448268648962\n","step: 428600\n","Step: 428600 -- Time: 17792 => ppl: 10.424561209356838\n","step: 428700\n","Step: 428700 -- Time: 17823 => ppl: 9.922344521296898\n","step: 428800\n","Step: 428800 -- Time: 17853 => ppl: 10.977202329020193\n","step: 428900\n","Step: 428900 -- Time: 17885 => ppl: 10.44840337458527\n","step: 429000\n","Step: 429000 -- Time: 17916 => ppl: 10.42784122062772\n","\n","1.1910038  3.0550551\n","\n","step: 429100\n","Step: 429100 -- Time: 17946 => ppl: 10.947439267329571\n","step: 429200\n","Step: 429200 -- Time: 17975 => ppl: 10.635371905308038\n","step: 429300\n","Step: 429300 -- Time: 18004 => ppl: 10.786512771334488\n","step: 429400\n","Step: 429400 -- Time: 18034 => ppl: 10.845135931962705\n","step: 429500\n","Step: 429500 -- Time: 18063 => ppl: 10.646403537693937\n","step: 429600\n","Step: 429600 -- Time: 18095 => ppl: 10.98983223474866\n","step: 429700\n","Step: 429700 -- Time: 18124 => ppl: 10.14086618298936\n","step: 429800\n","Step: 429800 -- Time: 18155 => ppl: 10.692790597375762\n","step: 429900\n","Step: 429900 -- Time: 18183 => ppl: 10.431680337116646\n","step: 430000\n","Step: 430000 -- Time: 18214 => ppl: 11.045863411707868\n","validation\n","### Step: 430000 -- Time: 18263 => ppl: 10.909459891069737\n","cnt 86\n","\n","1.253547  2.0939436\n","\n","step: 430100\n","Step: 430100 -- Time: 18296 => ppl: 10.04121702823676\n","step: 430200\n","Step: 430200 -- Time: 18325 => ppl: 10.58719277009162\n","step: 430300\n","Step: 430300 -- Time: 18356 => ppl: 11.041237335051099\n","step: 430400\n","Step: 430400 -- Time: 18386 => ppl: 11.269660341936955\n","step: 430500\n","Step: 430500 -- Time: 18416 => ppl: 11.229801838828786\n","step: 430600\n","Step: 430600 -- Time: 18447 => ppl: 10.735486542785386\n","step: 430700\n","Step: 430700 -- Time: 18475 => ppl: 10.44367002361556\n","step: 430800\n","Step: 430800 -- Time: 18502 => ppl: 9.768719242725808\n","step: 430900\n","Step: 430900 -- Time: 18532 => ppl: 10.929730829032378\n","step: 431000\n","Step: 431000 -- Time: 18563 => ppl: 11.30023087876168\n","\n","2.611323  4.4902234\n","\n","step: 431100\n","Step: 431100 -- Time: 18592 => ppl: 10.403582763957695\n","step: 431200\n","Step: 431200 -- Time: 18623 => ppl: 10.387230925994512\n","step: 431300\n","Step: 431300 -- Time: 18653 => ppl: 10.519338345877854\n","step: 431400\n","Step: 431400 -- Time: 18684 => ppl: 11.713555752068485\n","step: 431500\n","Step: 431500 -- Time: 18712 => ppl: 10.83823890006268\n","step: 431600\n","Step: 431600 -- Time: 18742 => ppl: 10.862426504344997\n","step: 431700\n","Step: 431700 -- Time: 18771 => ppl: 10.58381290082046\n","step: 431800\n","Step: 431800 -- Time: 18801 => ppl: 10.375873869311883\n","step: 431900\n","Step: 431900 -- Time: 18831 => ppl: 11.136171734816937\n","step: 432000\n","Step: 432000 -- Time: 18861 => ppl: 10.21985509190339\n","\n","2.183002  3.1540782\n","\n","step: 432100\n","Step: 432100 -- Time: 18891 => ppl: 11.402308526582042\n","step: 432200\n","Step: 432200 -- Time: 18921 => ppl: 10.421870786669404\n","step: 432300\n","Step: 432300 -- Time: 18951 => ppl: 10.236874921643697\n","step: 432400\n","Step: 432400 -- Time: 18982 => ppl: 11.468560121521012\n","step: 432500\n","Step: 432500 -- Time: 19010 => ppl: 10.462630861626876\n","step: 432600\n","Step: 432600 -- Time: 19041 => ppl: 10.925790237506204\n","step: 432700\n","Step: 432700 -- Time: 19070 => ppl: 11.067635909835015\n","step: 432800\n","Step: 432800 -- Time: 19099 => ppl: 10.512693546884321\n","step: 432900\n","Step: 432900 -- Time: 19127 => ppl: 10.748270884296138\n","step: 433000\n","Step: 433000 -- Time: 19157 => ppl: 10.489466653882925\n","\n","1.6905869  3.9413059\n","\n","step: 433100\n","Step: 433100 -- Time: 19187 => ppl: 10.420406211605865\n","step: 433200\n","Step: 433200 -- Time: 19217 => ppl: 10.4461318960079\n","step: 433300\n","Step: 433300 -- Time: 19247 => ppl: 10.362703142223502\n","step: 433400\n","Step: 433400 -- Time: 19276 => ppl: 10.466251772471079\n","step: 433500\n","Step: 433500 -- Time: 19306 => ppl: 10.342267948920817\n","step: 433600\n","Step: 433600 -- Time: 19335 => ppl: 10.42023847495754\n","step: 433700\n","Step: 433700 -- Time: 19364 => ppl: 10.812207273189431\n","step: 433800\n","Step: 433800 -- Time: 19393 => ppl: 10.0901001129687\n","step: 433900\n","Step: 433900 -- Time: 19421 => ppl: 10.818222082927425\n","step: 434000\n","Step: 434000 -- Time: 19449 => ppl: 10.57708773980422\n","\n","1.3571934  4.1362786\n","\n","step: 434100\n","Step: 434100 -- Time: 19478 => ppl: 10.182264034943959\n","step: 434200\n","Step: 434200 -- Time: 19508 => ppl: 10.385252363875843\n","step: 434300\n","Step: 434300 -- Time: 19537 => ppl: 10.56933743110004\n","step: 434400\n","Step: 434400 -- Time: 19565 => ppl: 10.042078594124856\n","step: 434500\n","Step: 434500 -- Time: 19595 => ppl: 11.27063788198144\n","step: 434600\n","Step: 434600 -- Time: 19624 => ppl: 10.631849359089804\n","step: 434700\n","Step: 434700 -- Time: 19654 => ppl: 11.25772039880731\n","step: 434800\n","Step: 434800 -- Time: 19684 => ppl: 10.326715614060323\n","step: 434900\n","Step: 434900 -- Time: 19712 => ppl: 10.404021208678667\n","step: 435000\n","Step: 435000 -- Time: 19743 => ppl: 11.033404179467148\n","validation\n","### Step: 435000 -- Time: 19789 => ppl: 10.912984804035393\n","cnt 87\n","\n","1.7782103  2.8129554\n","\n","step: 435100\n","Step: 435100 -- Time: 19822 => ppl: 10.405365731802627\n","step: 435200\n","Step: 435200 -- Time: 19854 => ppl: 10.56898439805716\n","step: 435300\n","Step: 435300 -- Time: 19882 => ppl: 10.291687337640553\n","step: 435400\n","Step: 435400 -- Time: 19912 => ppl: 10.014308911436025\n","step: 435500\n","Step: 435500 -- Time: 19944 => ppl: 10.81872000850971\n","step: 435600\n","Step: 435600 -- Time: 19974 => ppl: 10.833507314978762\n","step: 435700\n","Step: 435700 -- Time: 20003 => ppl: 10.324759012693216\n","step: 435800\n","Step: 435800 -- Time: 20033 => ppl: 11.061338985694652\n","step: 435900\n","Step: 435900 -- Time: 20061 => ppl: 9.952791069849958\n","step: 436000\n","Step: 436000 -- Time: 20090 => ppl: 11.037693153373192\n","\n","1.2235032  3.0706985\n","\n","step: 436100\n","Step: 436100 -- Time: 20117 => ppl: 10.413219988187219\n","step: 436200\n","Step: 436200 -- Time: 20147 => ppl: 9.988820033012265\n","step: 436300\n","Step: 436300 -- Time: 20176 => ppl: 10.498689494118965\n","step: 436400\n","Step: 436400 -- Time: 20206 => ppl: 10.801887574202214\n","step: 436500\n","Step: 436500 -- Time: 20237 => ppl: 11.313980505341972\n","step: 436600\n","Step: 436600 -- Time: 20264 => ppl: 10.52032008450401\n","step: 436700\n","Step: 436700 -- Time: 20292 => ppl: 10.63553518692234\n","step: 436800\n","Step: 436800 -- Time: 20323 => ppl: 11.07719861360675\n","step: 436900\n","Step: 436900 -- Time: 20352 => ppl: 9.874134994898684\n","step: 437000\n","Step: 437000 -- Time: 20382 => ppl: 11.319546722155888\n","\n","1.4225769  2.6719656\n","\n","step: 437100\n","Step: 437100 -- Time: 20414 => ppl: 10.783689834961265\n","step: 437200\n","Step: 437200 -- Time: 20442 => ppl: 10.93835937279239\n","step: 437300\n","Step: 437300 -- Time: 20469 => ppl: 9.81590056804738\n","step: 437400\n","Step: 437400 -- Time: 20499 => ppl: 10.603686539133035\n","step: 437500\n","Step: 437500 -- Time: 20527 => ppl: 11.24446075435654\n","step: 437600\n","Step: 437600 -- Time: 20556 => ppl: 10.703496348255177\n","step: 437700\n","Step: 437700 -- Time: 20583 => ppl: 10.212086560189778\n","step: 437800\n","Step: 437800 -- Time: 20612 => ppl: 10.42638245753629\n","step: 437900\n","Step: 437900 -- Time: 20641 => ppl: 10.910725967076669\n","step: 438000\n","Step: 438000 -- Time: 20672 => ppl: 10.952031673171202\n","\n","1.1149126  2.0409532\n","\n","step: 438100\n","Step: 438100 -- Time: 20702 => ppl: 10.574189214131732\n","step: 438200\n","Step: 438200 -- Time: 20731 => ppl: 10.863972900011099\n","step: 438300\n","Step: 438300 -- Time: 20761 => ppl: 10.355852361169653\n","step: 438400\n","Step: 438400 -- Time: 20789 => ppl: 10.320594101891029\n","step: 438500\n","Step: 438500 -- Time: 20819 => ppl: 10.101556023093789\n","step: 438600\n","Step: 438600 -- Time: 20848 => ppl: 10.552167433636097\n","step: 438700\n","Step: 438700 -- Time: 20877 => ppl: 11.24086508562859\n","step: 438800\n","Step: 438800 -- Time: 20906 => ppl: 10.794279996259048\n","step: 438900\n","Step: 438900 -- Time: 20936 => ppl: 10.572596574421336\n","step: 439000\n","Step: 439000 -- Time: 20967 => ppl: 10.853896019995434\n","\n","1.1143831  2.0660121\n","\n","step: 439100\n","Step: 439100 -- Time: 20994 => ppl: 10.208656913264642\n","step: 439200\n","Step: 439200 -- Time: 21024 => ppl: 10.422616435646201\n","step: 439300\n","Step: 439300 -- Time: 21055 => ppl: 10.36159260781546\n","step: 439400\n","Step: 439400 -- Time: 21083 => ppl: 10.308148798435356\n","step: 439500\n","Step: 439500 -- Time: 21112 => ppl: 10.280110584788973\n","step: 439600\n","Step: 439600 -- Time: 21141 => ppl: 10.103711315594753\n","step: 439700\n","Step: 439700 -- Time: 21168 => ppl: 10.118371191127956\n","step: 439800\n","Step: 439800 -- Time: 21200 => ppl: 10.2428198222073\n","step: 439900\n","Step: 439900 -- Time: 21229 => ppl: 10.63136883634682\n","step: 440000\n","Step: 440000 -- Time: 21259 => ppl: 10.724520206886169\n","validation\n","### Step: 440000 -- Time: 21306 => ppl: 10.86736264231843\n","cnt 88\n","\n","1.7096618  3.3191807\n","\n","step: 440100\n","Step: 440100 -- Time: 21338 => ppl: 10.820291796524254\n","step: 440200\n","Step: 440200 -- Time: 21368 => ppl: 10.476892023470562\n","step: 440300\n","Step: 440300 -- Time: 21396 => ppl: 10.763986386383248\n","step: 440400\n","Step: 440400 -- Time: 21424 => ppl: 10.735624003842926\n","step: 440500\n","Step: 440500 -- Time: 21453 => ppl: 10.634582010971748\n","step: 440600\n","Step: 440600 -- Time: 21484 => ppl: 11.407342595322529\n","step: 440700\n","Step: 440700 -- Time: 21514 => ppl: 10.316199375994847\n","step: 440800\n","Step: 440800 -- Time: 21543 => ppl: 10.584873223941793\n","step: 440900\n","Step: 440900 -- Time: 21574 => ppl: 10.763962798892411\n","step: 441000\n","Step: 441000 -- Time: 21602 => ppl: 10.307141081657283\n","\n","2.3474524  5.1057267\n","\n","step: 441100\n","Step: 441100 -- Time: 21630 => ppl: 10.464651723255383\n","step: 441200\n","Step: 441200 -- Time: 21661 => ppl: 11.42106157027877\n","step: 441300\n","Step: 441300 -- Time: 21688 => ppl: 10.882279008020893\n","step: 441400\n","Step: 441400 -- Time: 21721 => ppl: 10.538923125555845\n","step: 441500\n","Step: 441500 -- Time: 21751 => ppl: 10.891077764408154\n","step: 441600\n","Step: 441600 -- Time: 21778 => ppl: 10.55869305160001\n","step: 441700\n","Step: 441700 -- Time: 21807 => ppl: 10.305262901130844\n","step: 441800\n","Step: 441800 -- Time: 21834 => ppl: 10.314411411222805\n","step: 441900\n","Step: 441900 -- Time: 21866 => ppl: 11.061064681268443\n","step: 442000\n","Step: 442000 -- Time: 21896 => ppl: 10.213608832915769\n","\n","2.150954  4.102912\n","\n","step: 442100\n","Step: 442100 -- Time: 21925 => ppl: 10.93406790729814\n","step: 442200\n","Step: 442200 -- Time: 21958 => ppl: 11.070436707651083\n","step: 442300\n","Step: 442300 -- Time: 21987 => ppl: 10.48639340054762\n","step: 442400\n","Step: 442400 -- Time: 22016 => ppl: 10.575691167715949\n","step: 442500\n","Step: 442500 -- Time: 22047 => ppl: 11.468577103284312\n","step: 442600\n","Step: 442600 -- Time: 22074 => ppl: 10.788059208266116\n","step: 442700\n","Step: 442700 -- Time: 22104 => ppl: 10.28435729186007\n","step: 442800\n","Step: 442800 -- Time: 22131 => ppl: 10.75235106599066\n","step: 442900\n","Step: 442900 -- Time: 22162 => ppl: 10.503586784450917\n","step: 443000\n","Step: 443000 -- Time: 22192 => ppl: 10.324922217853736\n","\n","2.7397916  4.444255\n","\n","step: 443100\n","Step: 443100 -- Time: 22223 => ppl: 11.36306534649749\n","step: 443200\n","Step: 443200 -- Time: 22252 => ppl: 10.87471720376679\n","step: 443300\n","Step: 443300 -- Time: 22281 => ppl: 10.612844617431923\n","step: 443400\n","Step: 443400 -- Time: 22310 => ppl: 10.602911263675379\n","step: 443500\n","Step: 443500 -- Time: 22340 => ppl: 10.889851199418825\n","step: 443600\n","Step: 443600 -- Time: 22371 => ppl: 11.77851026247324\n","step: 443700\n","Step: 443700 -- Time: 22403 => ppl: 11.267219911788594\n","step: 443800\n","Step: 443800 -- Time: 22434 => ppl: 10.337189520413121\n","step: 443900\n","Step: 443900 -- Time: 22462 => ppl: 10.142208183654999\n","step: 444000\n","Step: 444000 -- Time: 22491 => ppl: 10.575369668948825\n","\n","1.1422535  2.031544\n","\n","step: 444100\n","Step: 444100 -- Time: 22520 => ppl: 10.416960794829615\n","step: 444200\n","Step: 444200 -- Time: 22552 => ppl: 10.363345978051939\n","step: 444300\n","Step: 444300 -- Time: 22579 => ppl: 9.951917954956324\n","step: 444400\n","Step: 444400 -- Time: 22609 => ppl: 10.587365530031162\n","step: 444500\n","Step: 444500 -- Time: 22637 => ppl: 10.187900771438338\n","step: 444600\n","Step: 444600 -- Time: 22667 => ppl: 11.03320997391283\n","step: 444700\n","Step: 444700 -- Time: 22695 => ppl: 10.425520000663836\n","step: 444800\n","Step: 444800 -- Time: 22725 => ppl: 10.731139739291896\n","step: 444900\n","Step: 444900 -- Time: 22753 => ppl: 10.159582090080143\n","step: 445000\n","Step: 445000 -- Time: 22782 => ppl: 11.07950256426413\n","validation\n","### Step: 445000 -- Time: 22829 => ppl: 10.630486781060679\n","cnt 89\n","\n","0.8865088  1.811549\n","\n","step: 445100\n","Step: 445100 -- Time: 22863 => ppl: 10.558738210247057\n","step: 445200\n","Step: 445200 -- Time: 22893 => ppl: 10.707947162696838\n","step: 445300\n","Step: 445300 -- Time: 22922 => ppl: 10.150247437284865\n","step: 445400\n","Step: 445400 -- Time: 22954 => ppl: 10.171800528686225\n","step: 445500\n","Step: 445500 -- Time: 22983 => ppl: 10.374776385467651\n","step: 445600\n","Step: 445600 -- Time: 23013 => ppl: 10.607811433143212\n","step: 445700\n","Step: 445700 -- Time: 23043 => ppl: 10.207925516914099\n","step: 445800\n","Step: 445800 -- Time: 23071 => ppl: 10.043733255838635\n","step: 445900\n","Step: 445900 -- Time: 23101 => ppl: 10.607766380160498\n","step: 446000\n","Step: 446000 -- Time: 23132 => ppl: 10.333930560072108\n","\n","1.8732109  3.314352\n","\n","step: 446100\n","Step: 446100 -- Time: 23158 => ppl: 10.491794508432116\n","step: 446200\n","Step: 446200 -- Time: 23189 => ppl: 10.078788060984982\n","step: 446300\n","Step: 446300 -- Time: 23220 => ppl: 10.581298680986766\n","step: 446400\n","Step: 446400 -- Time: 23249 => ppl: 10.57017417628642\n","step: 446500\n","Step: 446500 -- Time: 23279 => ppl: 10.192440533219191\n","step: 446600\n","Step: 446600 -- Time: 23309 => ppl: 10.32263015964274\n","step: 446700\n","Step: 446700 -- Time: 23339 => ppl: 10.413523521434096\n","step: 446800\n","Step: 446800 -- Time: 23370 => ppl: 10.967458706509374\n","step: 446900\n","Step: 446900 -- Time: 23399 => ppl: 10.016846073977767\n","step: 447000\n","Step: 447000 -- Time: 23427 => ppl: 10.101072934294598\n","\n","2.0877323  4.2662907\n","\n","step: 447100\n","Step: 447100 -- Time: 23457 => ppl: 11.011136396253205\n","step: 447200\n","Step: 447200 -- Time: 23485 => ppl: 10.566637208106322\n","step: 447300\n","Step: 447300 -- Time: 23512 => ppl: 10.847825396349492\n","step: 447400\n","Step: 447400 -- Time: 23542 => ppl: 11.100447358842441\n","step: 447500\n","Step: 447500 -- Time: 23570 => ppl: 10.020890774374367\n","step: 447600\n","Step: 447600 -- Time: 23601 => ppl: 10.572492929928458\n","step: 447700\n","Step: 447700 -- Time: 23635 => ppl: 10.71497863033607\n","step: 447800\n","Step: 447800 -- Time: 23663 => ppl: 10.98878462672575\n","step: 447900\n","Step: 447900 -- Time: 23693 => ppl: 10.60660714682456\n","step: 448000\n","Step: 448000 -- Time: 23721 => ppl: 10.438892342048014\n","\n","0.9915325  2.0094512\n","\n","step: 448100\n","Step: 448100 -- Time: 23752 => ppl: 10.553042939867677\n","step: 448200\n","Step: 448200 -- Time: 23780 => ppl: 10.591032400764394\n","step: 448300\n","Step: 448300 -- Time: 23808 => ppl: 9.961928961663258\n","step: 448400\n","Step: 448400 -- Time: 23839 => ppl: 10.68905514460308\n","step: 448500\n","Step: 448500 -- Time: 23869 => ppl: 9.908310597068445\n","step: 448600\n","Step: 448600 -- Time: 23899 => ppl: 10.100357892099654\n","step: 448700\n","Step: 448700 -- Time: 23929 => ppl: 10.405043985777548\n","step: 448800\n","Step: 448800 -- Time: 23957 => ppl: 10.484547479285588\n","step: 448900\n","Step: 448900 -- Time: 23986 => ppl: 9.292222527519135\n","step: 449000\n","Step: 449000 -- Time: 24017 => ppl: 10.743962680224701\n","\n","1.3069928  2.2715132\n","\n","step: 449100\n","Step: 449100 -- Time: 24047 => ppl: 10.84185231330612\n","step: 449200\n","Step: 449200 -- Time: 24075 => ppl: 10.6074618743466\n","step: 449300\n","Step: 449300 -- Time: 24102 => ppl: 10.865434223891906\n","step: 449400\n","Step: 449400 -- Time: 24132 => ppl: 10.029699565010109\n","step: 449500\n","Step: 449500 -- Time: 24161 => ppl: 10.621509410914799\n","step: 449600\n","Step: 449600 -- Time: 24188 => ppl: 10.089105109104223\n","step: 449700\n","Step: 449700 -- Time: 24218 => ppl: 10.239517697342679\n","step: 449800\n","Step: 449800 -- Time: 24248 => ppl: 10.00584308728863\n","step: 449900\n","Step: 449900 -- Time: 24277 => ppl: 10.070139618307282\n","step: 450000\n","Step: 450000 -- Time: 24306 => ppl: 10.282082012644882\n","validation\n","### Step: 450000 -- Time: 24352 => ppl: 10.745495879940824\n","cnt 90\n","\n","1.3245399  2.3452158\n","\n","step: 450100\n","Step: 450100 -- Time: 24382 => ppl: 10.580805081716505\n","step: 450200\n","Step: 450200 -- Time: 24408 => ppl: 9.950058593612068\n","step: 450300\n","Step: 450300 -- Time: 24439 => ppl: 11.125925539057244\n","step: 450400\n","Step: 450400 -- Time: 24467 => ppl: 10.021717936272683\n","step: 450500\n","Step: 450500 -- Time: 24496 => ppl: 10.37704029657653\n","step: 450600\n","Step: 450600 -- Time: 24524 => ppl: 10.808569828806835\n","step: 450700\n","Step: 450700 -- Time: 24553 => ppl: 9.83528170611986\n","step: 450800\n","Step: 450800 -- Time: 24582 => ppl: 10.510166937490107\n","step: 450900\n","Step: 450900 -- Time: 24611 => ppl: 10.879873127593916\n","step: 451000\n","Step: 451000 -- Time: 24640 => ppl: 10.235591582423476\n","\n","1.8471864  3.047633\n","\n","step: 451100\n","Step: 451100 -- Time: 24670 => ppl: 10.641958633315546\n","step: 451200\n","Step: 451200 -- Time: 24699 => ppl: 10.460671984434189\n","step: 451300\n","Step: 451300 -- Time: 24729 => ppl: 10.354822979849475\n","step: 451400\n","Step: 451400 -- Time: 24758 => ppl: 10.126538265258356\n","step: 451500\n","Step: 451500 -- Time: 24788 => ppl: 9.545559328228492\n","step: 451600\n","Step: 451600 -- Time: 24817 => ppl: 9.594608620530677\n","step: 451700\n","Step: 451700 -- Time: 24846 => ppl: 10.352401402847057\n","step: 451800\n","Step: 451800 -- Time: 24877 => ppl: 10.134242229536595\n","step: 451900\n","Step: 451900 -- Time: 24904 => ppl: 9.857200630575468\n","step: 452000\n","Step: 452000 -- Time: 24932 => ppl: 10.275822939124199\n","\n","1.9808906  3.9171863\n","\n","step: 452100\n","Step: 452100 -- Time: 24961 => ppl: 10.69094328193261\n","step: 452200\n","Step: 452200 -- Time: 24992 => ppl: 10.013849547466588\n","step: 452300\n","Step: 452300 -- Time: 25021 => ppl: 11.262255896447524\n","step: 452400\n","Step: 452400 -- Time: 25048 => ppl: 10.42877995101226\n","step: 452500\n","Step: 452500 -- Time: 25077 => ppl: 10.085212374741037\n","step: 452600\n","Step: 452600 -- Time: 25104 => ppl: 10.316014367711189\n","step: 452700\n","Step: 452700 -- Time: 25134 => ppl: 10.50613669222172\n","step: 452800\n","Step: 452800 -- Time: 25162 => ppl: 10.17782234862475\n","step: 452900\n","Step: 452900 -- Time: 25192 => ppl: 10.372267993005437\n","step: 453000\n","Step: 453000 -- Time: 25220 => ppl: 11.074443670625062\n","\n","1.4658338  2.94463\n","\n","step: 453100\n","Step: 453100 -- Time: 25249 => ppl: 10.23337519688824\n","step: 453200\n","Step: 453200 -- Time: 25277 => ppl: 10.121318172193275\n","step: 453300\n","Step: 453300 -- Time: 25306 => ppl: 10.158472968202837\n","step: 453400\n","Step: 453400 -- Time: 25336 => ppl: 10.836723818381914\n","step: 453500\n","Step: 453500 -- Time: 25363 => ppl: 10.066759547967601\n","step: 453600\n","Step: 453600 -- Time: 25395 => ppl: 11.402299670206299\n","step: 453700\n","Step: 453700 -- Time: 25424 => ppl: 9.961592229022237\n","step: 453800\n","Step: 453800 -- Time: 25451 => ppl: 10.15554765232691\n","step: 453900\n","Step: 453900 -- Time: 25479 => ppl: 9.734614953538095\n","step: 454000\n","Step: 454000 -- Time: 25507 => ppl: 10.169106126541479\n","\n","0.862161  1.8954049\n","\n","step: 454100\n","Step: 454100 -- Time: 25537 => ppl: 10.377747391507437\n","step: 454200\n","Step: 454200 -- Time: 25566 => ppl: 10.686625860974106\n","step: 454300\n","Step: 454300 -- Time: 25597 => ppl: 10.965702705686518\n","step: 454400\n","Step: 454400 -- Time: 25625 => ppl: 10.172993836247388\n","step: 454500\n","Step: 454500 -- Time: 25653 => ppl: 10.41708649939044\n","step: 454600\n","Step: 454600 -- Time: 25682 => ppl: 10.127592150204162\n","step: 454700\n","Step: 454700 -- Time: 25711 => ppl: 10.25152636878399\n","step: 454800\n","Step: 454800 -- Time: 25741 => ppl: 10.303642646371063\n","step: 454900\n","Step: 454900 -- Time: 25770 => ppl: 10.30890915680566\n","step: 455000\n","Step: 455000 -- Time: 25799 => ppl: 10.568557436311481\n","validation\n","### Step: 455000 -- Time: 25846 => ppl: 10.595725237742975\n","cnt 91\n","\n","1.1047555  1.7869866\n","\n","step: 455100\n","Step: 455100 -- Time: 25878 => ppl: 10.81419191142516\n","step: 455200\n","Step: 455200 -- Time: 25905 => ppl: 9.82697459964487\n","step: 455300\n","Step: 455300 -- Time: 25935 => ppl: 10.496062574650061\n","step: 455400\n","Step: 455400 -- Time: 25965 => ppl: 10.059687421110677\n","step: 455500\n","Step: 455500 -- Time: 25993 => ppl: 10.033088746642123\n","step: 455600\n","Step: 455600 -- Time: 26018 => ppl: 9.718061404870715\n","step: 455700\n","Step: 455700 -- Time: 26046 => ppl: 9.944624700951055\n","step: 455800\n","Step: 455800 -- Time: 26076 => ppl: 10.195695176049073\n","step: 455900\n","Step: 455900 -- Time: 26106 => ppl: 10.070683820811164\n","step: 456000\n","Step: 456000 -- Time: 26136 => ppl: 10.677875010303355\n","\n","1.3684117  2.1584127\n","\n","step: 456100\n","Step: 456100 -- Time: 26164 => ppl: 10.238058512637346\n","step: 456200\n","Step: 456200 -- Time: 26194 => ppl: 10.571882422983657\n","step: 456300\n","Step: 456300 -- Time: 26225 => ppl: 10.24862746330704\n","step: 456400\n","Step: 456400 -- Time: 26254 => ppl: 10.239016817583272\n","step: 456500\n","Step: 456500 -- Time: 26282 => ppl: 10.000372590178195\n","step: 456600\n","Step: 456600 -- Time: 26313 => ppl: 10.735360562017046\n","step: 456700\n","Step: 456700 -- Time: 26342 => ppl: 10.003397626135452\n","step: 456800\n","Step: 456800 -- Time: 26372 => ppl: 9.654297095680484\n","step: 456900\n","Step: 456900 -- Time: 26399 => ppl: 10.414253815170886\n","step: 457000\n","Step: 457000 -- Time: 26428 => ppl: 10.234235162029158\n","\n","0.9950431  2.0182998\n","\n","step: 457100\n","Step: 457100 -- Time: 26458 => ppl: 10.285581269340987\n","step: 457200\n","Step: 457200 -- Time: 26486 => ppl: 9.756585488337535\n","step: 457300\n","Step: 457300 -- Time: 26514 => ppl: 9.77845886128465\n","step: 457400\n","Step: 457400 -- Time: 26545 => ppl: 10.004308588058942\n","step: 457500\n","Step: 457500 -- Time: 26575 => ppl: 9.936416574628533\n","step: 457600\n","Step: 457600 -- Time: 26605 => ppl: 9.974819023992417\n","step: 457700\n","Step: 457700 -- Time: 26633 => ppl: 10.669294226035367\n","step: 457800\n","Step: 457800 -- Time: 26663 => ppl: 9.90246874170074\n","step: 457900\n","Step: 457900 -- Time: 26691 => ppl: 9.86516483154198\n","step: 458000\n","Step: 458000 -- Time: 26719 => ppl: 10.45677421811189\n","\n","1.2676852  2.3477566\n","\n","step: 458100\n","Step: 458100 -- Time: 26750 => ppl: 10.282990857375037\n","step: 458200\n","Step: 458200 -- Time: 26779 => ppl: 10.303456994879031\n","step: 458300\n","Step: 458300 -- Time: 26808 => ppl: 10.54001728917051\n","step: 458400\n","Step: 458400 -- Time: 26838 => ppl: 10.520639153419603\n","step: 458500\n","Step: 458500 -- Time: 26869 => ppl: 10.740180357590175\n","step: 458600\n","Step: 458600 -- Time: 26898 => ppl: 10.173674501745253\n","step: 458700\n","Step: 458700 -- Time: 26928 => ppl: 10.677625417008858\n","step: 458800\n","Step: 458800 -- Time: 26956 => ppl: 10.357277669983608\n","step: 458900\n","Step: 458900 -- Time: 26984 => ppl: 9.871996576316334\n","step: 459000\n","Step: 459000 -- Time: 27013 => ppl: 10.534846981506396\n","\n","1.0199735  2.1405735\n","\n","step: 459100\n","Step: 459100 -- Time: 27042 => ppl: 9.956990989358822\n","step: 459200\n","Step: 459200 -- Time: 27070 => ppl: 10.036741752640188\n","step: 459300\n","Step: 459300 -- Time: 27100 => ppl: 10.222837331992242\n","step: 459400\n","Step: 459400 -- Time: 27129 => ppl: 9.833568568597967\n","step: 459500\n","Step: 459500 -- Time: 27156 => ppl: 10.222929270509852\n","step: 459600\n","Step: 459600 -- Time: 27184 => ppl: 10.232373335666026\n","step: 459700\n","Step: 459700 -- Time: 27215 => ppl: 11.13600110766108\n","step: 459800\n","Step: 459800 -- Time: 27244 => ppl: 9.738059798806873\n","step: 459900\n","Step: 459900 -- Time: 27271 => ppl: 10.58725535456482\n","step: 460000\n","Step: 460000 -- Time: 27302 => ppl: 10.8102488854262\n","validation\n","### Step: 460000 -- Time: 27346 => ppl: 10.656173239551206\n","cnt 92\n","\n","1.0065374  1.9131411\n","\n","step: 460100\n","Step: 460100 -- Time: 27378 => ppl: 9.880610343592966\n","step: 460200\n","Step: 460200 -- Time: 27406 => ppl: 9.998899738402523\n","step: 460300\n","Step: 460300 -- Time: 27437 => ppl: 10.154751591579844\n","step: 460400\n","Step: 460400 -- Time: 27465 => ppl: 9.989357372912126\n","step: 460500\n","Step: 460500 -- Time: 27495 => ppl: 10.409426009933572\n","step: 460600\n","Step: 460600 -- Time: 27524 => ppl: 10.306557317718791\n","step: 460700\n","Step: 460700 -- Time: 27555 => ppl: 10.633890955370749\n","step: 460800\n","Step: 460800 -- Time: 27583 => ppl: 10.432711065917799\n","step: 460900\n","Step: 460900 -- Time: 27614 => ppl: 9.835289629804\n","step: 461000\n","Step: 461000 -- Time: 27644 => ppl: 9.860096541632718\n","\n","3.0473745  8.248037\n","\n","step: 461100\n","Step: 461100 -- Time: 27675 => ppl: 9.63377444256819\n","step: 461200\n","Step: 461200 -- Time: 27705 => ppl: 10.351770784741685\n","step: 461300\n","Step: 461300 -- Time: 27737 => ppl: 11.212513121577114\n","step: 461400\n","Step: 461400 -- Time: 27766 => ppl: 10.183706524578445\n","step: 461500\n","Step: 461500 -- Time: 27796 => ppl: 10.283118998300532\n","step: 461600\n","Step: 461600 -- Time: 27825 => ppl: 10.256775589042341\n","step: 461700\n","Step: 461700 -- Time: 27853 => ppl: 9.949839833238338\n","step: 461800\n","Step: 461800 -- Time: 27883 => ppl: 10.313400201807257\n","step: 461900\n","Step: 461900 -- Time: 27913 => ppl: 10.271661387919593\n","step: 462000\n","Step: 462000 -- Time: 27943 => ppl: 10.445609317778592\n","\n","1.2041376  2.6930983\n","\n","step: 462100\n","Step: 462100 -- Time: 27973 => ppl: 9.993548767412632\n","step: 462200\n","Step: 462200 -- Time: 28006 => ppl: 10.606111841131002\n","step: 462300\n","Step: 462300 -- Time: 28036 => ppl: 10.220433134293584\n","step: 462400\n","Step: 462400 -- Time: 28065 => ppl: 9.720399369768273\n","step: 462500\n","Step: 462500 -- Time: 28095 => ppl: 10.114478104901421\n","step: 462600\n","Step: 462600 -- Time: 28126 => ppl: 10.588563117002307\n","step: 462700\n","Step: 462700 -- Time: 28153 => ppl: 10.000914394164043\n","step: 462800\n","Step: 462800 -- Time: 28182 => ppl: 10.05434152053503\n","step: 462900\n","Step: 462900 -- Time: 28212 => ppl: 10.407949810642661\n","step: 463000\n","Step: 463000 -- Time: 28243 => ppl: 10.756664491338144\n","\n","1.6370785  2.6771169\n","\n","step: 463100\n","Step: 463100 -- Time: 28273 => ppl: 10.141169679405277\n","step: 463200\n","Step: 463200 -- Time: 28303 => ppl: 10.40104066113788\n","step: 463300\n","Step: 463300 -- Time: 28332 => ppl: 9.761052484034543\n","step: 463400\n","Step: 463400 -- Time: 28361 => ppl: 10.127845548137286\n","step: 463500\n","Step: 463500 -- Time: 28388 => ppl: 9.977834499881103\n","step: 463600\n","Step: 463600 -- Time: 28417 => ppl: 10.051660366578183\n","step: 463700\n","Step: 463700 -- Time: 28446 => ppl: 10.26233594250177\n","step: 463800\n","Step: 463800 -- Time: 28474 => ppl: 10.330236052869402\n","step: 463900\n","Step: 463900 -- Time: 28503 => ppl: 9.915179856555612\n","step: 464000\n","Step: 464000 -- Time: 28534 => ppl: 11.2208068409875\n","\n","1.950861  3.65426\n","\n","step: 464100\n","Step: 464100 -- Time: 28567 => ppl: 11.15309970886002\n","step: 464200\n","Step: 464200 -- Time: 28596 => ppl: 10.280468605026881\n","step: 464300\n","Step: 464300 -- Time: 28625 => ppl: 10.179855634718502\n","step: 464400\n","Step: 464400 -- Time: 28655 => ppl: 10.204842114054207\n","step: 464500\n","Step: 464500 -- Time: 28686 => ppl: 10.918816452396584\n","step: 464600\n","Step: 464600 -- Time: 28714 => ppl: 9.80474355395383\n","step: 464700\n","Step: 464700 -- Time: 28743 => ppl: 11.139261133804126\n","step: 464800\n","Step: 464800 -- Time: 28772 => ppl: 9.754658172738427\n","step: 464900\n","Step: 464900 -- Time: 28802 => ppl: 9.79077539342857\n","step: 465000\n","Step: 465000 -- Time: 28829 => ppl: 9.849056866181504\n","validation\n","### Step: 465000 -- Time: 28876 => ppl: 10.871385976649128\n","cnt 93\n","\n","1.2309831  2.2999716\n","\n","step: 465100\n","Step: 465100 -- Time: 28908 => ppl: 9.840048113664874\n","step: 465200\n","Step: 465200 -- Time: 28938 => ppl: 10.712285341783373\n","step: 465300\n","Step: 465300 -- Time: 28966 => ppl: 10.26990945150512\n","step: 465400\n","Step: 465400 -- Time: 28995 => ppl: 10.743148076375313\n","step: 465500\n","Step: 465500 -- Time: 29024 => ppl: 10.315202498121499\n","step: 465600\n","Step: 465600 -- Time: 29054 => ppl: 10.153030837120477\n","step: 465700\n","Step: 465700 -- Time: 29086 => ppl: 10.393000296553526\n","step: 465800\n","Step: 465800 -- Time: 29113 => ppl: 10.483584965989927\n","step: 465900\n","Step: 465900 -- Time: 29144 => ppl: 11.233685671972562\n","step: 466000\n","Step: 466000 -- Time: 29173 => ppl: 10.382362106869909\n","\n","1.0328771  2.040453\n","\n","step: 466100\n","Step: 466100 -- Time: 29203 => ppl: 10.55566856866747\n","step: 466200\n","Step: 466200 -- Time: 29232 => ppl: 10.215291277023896\n","step: 466300\n","Step: 466300 -- Time: 29262 => ppl: 10.7387729347347\n","step: 466400\n","Step: 466400 -- Time: 29293 => ppl: 9.939558213497754\n","step: 466500\n","Step: 466500 -- Time: 29323 => ppl: 10.317405463433634\n","step: 466600\n","Step: 466600 -- Time: 29352 => ppl: 9.81684161632206\n","step: 466700\n","Step: 466700 -- Time: 29382 => ppl: 10.329827169050821\n","step: 466800\n","Step: 466800 -- Time: 29411 => ppl: 9.99922510319176\n","step: 466900\n","Step: 466900 -- Time: 29441 => ppl: 10.397627516435897\n","step: 467000\n","Step: 467000 -- Time: 29469 => ppl: 10.169633173720028\n","\n","1.2235001  2.5439646\n","\n","step: 467100\n","Step: 467100 -- Time: 29499 => ppl: 10.277382898199543\n","step: 467200\n","Step: 467200 -- Time: 29529 => ppl: 10.048763824843881\n","step: 467300\n","Step: 467300 -- Time: 29557 => ppl: 9.503973020886251\n","step: 467400\n","Step: 467400 -- Time: 29585 => ppl: 10.670928166283318\n","step: 467500\n","Step: 467500 -- Time: 29615 => ppl: 10.15670347755466\n","step: 467600\n","Step: 467600 -- Time: 29644 => ppl: 9.95767653805806\n","step: 467700\n","Step: 467700 -- Time: 29674 => ppl: 9.94543555818867\n","step: 467800\n","Step: 467800 -- Time: 29704 => ppl: 9.811335471623824\n","step: 467900\n","Step: 467900 -- Time: 29735 => ppl: 9.966833624021653\n","step: 468000\n","Step: 468000 -- Time: 29765 => ppl: 10.317785772387898\n","\n","3.1635158  5.4830413\n","\n","step: 468100\n","Step: 468100 -- Time: 29793 => ppl: 10.320905220109818\n","step: 468200\n","Step: 468200 -- Time: 29824 => ppl: 10.724438148540381\n","step: 468300\n","Step: 468300 -- Time: 29853 => ppl: 10.220615279860924\n","step: 468400\n","Step: 468400 -- Time: 29882 => ppl: 10.189839006796273\n","step: 468500\n","Step: 468500 -- Time: 29910 => ppl: 10.087681554169492\n","step: 468600\n","Step: 468600 -- Time: 29942 => ppl: 10.306343050710408\n","step: 468700\n","Step: 468700 -- Time: 29971 => ppl: 9.993629114452835\n","step: 468800\n","Step: 468800 -- Time: 29997 => ppl: 9.136351260375452\n","step: 468900\n","Step: 468900 -- Time: 30026 => ppl: 10.768217014300323\n","step: 469000\n","Step: 469000 -- Time: 30056 => ppl: 10.791911922677434\n","\n","1.4513055  3.4400501\n","\n","step: 469100\n","Step: 469100 -- Time: 30087 => ppl: 10.820118776281657\n","step: 469200\n","Step: 469200 -- Time: 30117 => ppl: 10.64588965114189\n","step: 469300\n","Step: 469300 -- Time: 30148 => ppl: 10.296764733411528\n","step: 469400\n","Step: 469400 -- Time: 30177 => ppl: 9.841678195760116\n","step: 469500\n","Step: 469500 -- Time: 30205 => ppl: 9.835225151517614\n","step: 469600\n","Step: 469600 -- Time: 30234 => ppl: 9.915476516687235\n","step: 469700\n","Step: 469700 -- Time: 30263 => ppl: 9.842477194451469\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P77M_mDTQGf8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}